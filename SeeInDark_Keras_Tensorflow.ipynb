{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SeeInDark_Keras_Tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KashyapCKotak/AI-ML-experiments/blob/master/SeeInDark_Keras_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuMNVBqt0u-H",
        "colab_type": "code",
        "outputId": "12730672-115e-400b-d9a9-3ee4d85651e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import requests\n",
        "# import os\n",
        "\n",
        "# def download_file_from_google_drive(id, destination):\n",
        "#     URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "#     session = requests.Session()\n",
        "\n",
        "#     response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "#     token = get_confirm_token(response)\n",
        "\n",
        "#     if token:\n",
        "#         params = { 'id' : id, 'confirm' : token }\n",
        "#         response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "#     save_response_content(response, destination)    \n",
        "\n",
        "# def get_confirm_token(response):\n",
        "#     for key, value in response.cookies.items():\n",
        "#         if key.startswith('download_warning'):\n",
        "#             return value\n",
        "\n",
        "#     return None\n",
        "\n",
        "# def save_response_content(response, destination):\n",
        "#     CHUNK_SIZE = 32768\n",
        "\n",
        "#     with open(destination, \"wb\") as f:\n",
        "#         for chunk in response.iter_content(CHUNK_SIZE):\n",
        "#             if chunk: # filter out keep-alive new chunks\n",
        "#                 f.write(chunk)\n",
        "\n",
        "\n",
        "\n",
        "# print('Dowloading Sony subset... (25GB)')\n",
        "# download_file_from_google_drive('10kpAcvldtcb9G2ze5hTcF1odzu4V_Zvh', './Sony.zip')\n",
        "\n",
        "# #print('Dowloading Fuji subset... (52GB)')\n",
        "# #download_file_from_google_drive('12hvKCjwuilKTZPe9EZ7ZTb-azOmUA3HT', 'dataset/Fuji.zip')\n",
        "\n",
        "# os.system('unzip ./Sony.zip -d dataset')\n",
        "# #os.system('unzip dataset/Fuji.zip -d dataset')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dowloading Sony subset... (25GB)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsP1lrRN-HPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import shutil\n",
        "# shutil.rmtree('result_Sony', ignore_errors=True, onerror=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-_85I6g3eA5",
        "colab_type": "code",
        "outputId": "a45e6ed1-ec00-4408-eb2f-fd76141d66a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# os.system('unzip ./Sony.zip -d dataset')\n",
        "#os.system('unzip dataset/Fuji.zip -d dataset')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9yF04nOlUCP",
        "colab_type": "text"
      },
      "source": [
        "**Main Train Code:**\n",
        "================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_zLVCtYlfSH",
        "colab_type": "code",
        "outputId": "93ba2eac-0338-4d95-c647-f394f0cfd20a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "!pip install rawpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rawpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/04/997062d83766f5fbfa4dc0d20180c5085b55a74e69559e9cb6d4f1e9550e/rawpy-0.13.1-cp36-cp36m-manylinux1_x86_64.whl (682kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rawpy) (1.16.4)\n",
            "Installing collected packages: rawpy\n",
            "Successfully installed rawpy-0.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IogQOu0slZNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5f98c6e4-342b-4cde-9bff-b2a389d4a3bc"
      },
      "source": [
        "from __future__ import division\n",
        "import os, time, scipy.io\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "import numpy as np\n",
        "import rawpy\n",
        "import glob\n",
        "import keras\n",
        "import shutil\n",
        "import datetime as dt\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gTj24DXlazJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "shutil.rmtree('result_Sony', ignore_errors=True, onerror=None)\n",
        "\n",
        "input_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/short/'\n",
        "gt_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/long/'\n",
        "os.mkdir('result_Sony')\n",
        "checkpoint_dir = './result_Sony/'\n",
        "result_dir = './result_Sony/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1bgs9-jrfgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_fns = glob.glob(gt_dir + '0*.ARW')\n",
        "###\n",
        "# 0* is for Training images. 1 for Test and 2 for Validation\n",
        "###\n",
        "# train_ids = [int(os.path.basename(train_fn)[0:5]) for train_fn in train_fns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbi6fY6ZiBz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ps = 512  # just a random patch size for training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V56pWdxpiGxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save_freq = 500\n",
        "# DEBUG = 0\n",
        "# if DEBUG == 1:\n",
        "#     save_freq = 2\n",
        "#     train_ids = train_ids[0:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vexCrDNtiIrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lrelu(x): # not used. Used Kears LeakyReLU with alpha 0.2 instead\n",
        "    return tf.maximum(x * 0.2, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZkJ3o0ZiKQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" This cell contains the custom Lambda layers to be used in building the  keras mdoel \"\"\"\n",
        "def upsample_and_concat(x1,x2,output_channels,in_channels,layer):\n",
        "  print(\"layer:\",layer)\n",
        "  pool_size = 2\n",
        "  deconv_filter = tf.Variable(tf.truncated_normal([pool_size, pool_size, output_channels, in_channels], stddev=0.02))\n",
        "  print(\"x1 shape:\",x1.shape)\n",
        "  print(\"x2 shape:\",x2.shape)\n",
        "  deconvtf=tf.nn.conv2d_transpose(x1, deconv_filter, tf.shape(x2), strides=[1, pool_size, pool_size, 1])\n",
        "  print(\"deconvtf shape:\",deconvtf.shape)\n",
        "  #deconv=keras.layers.Conv2DTranspose(filters=output_channels,kernel_size=(pool_size, pool_size),strides=(pool_size, pool_size))(x1)\n",
        "  #print(\"deconvk shape:\",deconv.shape)\n",
        "\n",
        "  deconv_output = tf.concat([deconvtf, x2], 3)\n",
        "  print(\"deconv_output shape:\",deconv_output.shape)\n",
        "  deconv_output.set_shape([None, None, None, output_channels * 2])\n",
        "\n",
        "  return deconv_output\n",
        "\n",
        "def Depth_to_space_tf(input):\n",
        "  return tf.depth_to_space(input, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cRpNNVlYXKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testing code\n",
        "# t=tf.ones([1,450,350,4])\n",
        "# deconv_filter = tf.Variable(tf.truncated_normal([2, 2, 256, 512], stddev=0.02))\n",
        "# tf.nn.conv2d_transpose(t, deconv_filter, [1,450,350,], strides=[1, pool_size, pool_size, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUz7pW3dm8Qh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  inputs=keras.layers.Input(shape=(None, None, 4))\n",
        "  #definition: slim.conv2d(inputs,number of outputs, kernel shape)\n",
        "  #definition: slim.max_pool2d(inputsconv2d_transpose ,kernel_size, padding)\n",
        "  #conv1 = slim.conv2d(input, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_1')\n",
        "  conv1=keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same',name='conv1_1')(inputs)\n",
        "  conv1=keras.layers.LeakyReLU(alpha=0.2,name='conv1_1_relu')(conv1)\n",
        "  print(\"conv1 shape:\",conv1.shape)\n",
        "  #conv1 = slim.conv2d(conv1, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_2')\n",
        "  conv1=keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same',name='conv1_2')(conv1)\n",
        "  conv1=keras.layers.LeakyReLU(alpha=0.2,name='conv1_2_relu')(conv1)\n",
        "  print(\"conv1 shape:\",conv1.shape)\n",
        "  #pool1 = slim.max_pool2d(conv1, [2, 2], padding='SAME')\n",
        "  pool1=keras.layers.MaxPooling2D(pool_size=(2,2),padding=\"same\",name='pool1')(conv1)\n",
        "  print(\"conv1 shape after pool:\",pool1.shape)\n",
        "\n",
        "  #conv2 = slim.conv2d(pool1, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv2_1')\n",
        "  conv2=keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',name='conv2_1')(pool1)\n",
        "  conv2=keras.layers.LeakyReLU(alpha=0.2,name='conv2_1_relu')(conv2)\n",
        "  #conv2 = slim.conv2d(conv2, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv2_2')\n",
        "  conv2=keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',name='conv2_2')(conv2)\n",
        "  conv2=keras.layers.LeakyReLU(alpha=0.2,name='conv2_2_relu')(conv2)\n",
        "  #pool2 = slim.max_pool2d(conv2, [2, 2], padding='SAME')\n",
        "  pool2=keras.layers.MaxPooling2D(pool_size=(2,2),padding=\"same\",name='pool2')(conv2)\n",
        "\n",
        "  #conv3 = slim.conv2d(pool2, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv3_1')\n",
        "  conv3=keras.layers.Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',name='conv3_1')(pool2)\n",
        "  conv3=keras.layers.LeakyReLU(alpha=0.2,name='conv3_1_relu')(conv3)\n",
        "  #conv3 = slim.conv2d(conv3, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv3_2')\n",
        "  conv3=keras.layers.Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',name='conv3_2')(conv3)\n",
        "  conv3=keras.layers.LeakyReLU(alpha=0.2,name='conv3_2_relu')(conv3)\n",
        "  #pool3 = slim.max_pool2d(conv3, [2, 2], padding='SAME')\n",
        "  pool3=keras.layers.MaxPooling2D(pool_size=(2,2),padding=\"same\",name='pool3')(conv3)\n",
        "\n",
        "  #conv4 = slim.conv2d(pool3, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv4_1')\n",
        "  conv4=keras.layers.Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',name='conv4_1')(pool3)\n",
        "  conv4=keras.layers.LeakyReLU(alpha=0.2,name='conv4_1_relu')(conv4)\n",
        "  #conv4 = slim.conv2d(conv4, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv4_2')\n",
        "  conv4=keras.layers.Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',name='conv4_2')(conv4)\n",
        "  conv4=keras.layers.LeakyReLU(alpha=0.2,name='conv4_2_relu')(conv4)\n",
        "  #pool4 = slim.max_pool2d(conv4, [2, 2], padding='SAME')\n",
        "  pool4=keras.layers.MaxPooling2D(pool_size=(2,2),padding=\"same\",name='pool4')(conv4)\n",
        "\n",
        "  #conv5 = slim.conv2d(pool4, 512, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv5_1')\n",
        "  conv5=keras.layers.Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',name='conv5_1')(pool4)\n",
        "  conv5=keras.layers.LeakyReLU(alpha=0.2,name='conv5_1_relu')(conv5)\n",
        "  #conv5 = slim.conv2d(conv5, 512, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv5_2')\n",
        "  conv5=keras.layers.Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',name='conv5_2')(conv5)\n",
        "  conv5=keras.layers.LeakyReLU(alpha=0.2,name='conv5_2_relu')(conv5)\n",
        "\n",
        "  #up6 = upsample_and_concat(conv5, conv4, 256, 512)\n",
        "  up6=keras.layers.core.Lambda(upsample_and_concat,arguments={'x2':conv4,'output_channels':256,'in_channels':512,'layer':'upsample_concat_1'},name='upsample_concat_1')(conv5)\n",
        "  #conv6 = slim.conv2d(up6, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv6_1')\n",
        "  conv6=keras.layers.Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',name='conv6_1')(up6)\n",
        "  conv6=keras.layers.LeakyReLU(alpha=0.2,name='conv6_1_relu')(conv6)\n",
        "  #conv6 = slim.conv2d(conv6, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv6_2')\n",
        "  conv6=keras.layers.Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',name='conv6_2')(conv6)\n",
        "  conv6=keras.layers.LeakyReLU(alpha=0.2,name='conv6_2_relu')(conv6)\n",
        "\n",
        "  #up7 = upsample_and_concat(conv6, conv3, 128, 256)\n",
        "  up7=keras.layers.core.Lambda(upsample_and_concat,arguments={'x2':conv3,'output_channels':128,'in_channels':256,'layer':'upsample_concat_2'},name='upsample_concat_2')(conv6)\n",
        "  #conv7 = slim.conv2d(up7, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv7_1')\n",
        "  conv7=keras.layers.Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',name='conv7_1')(up7)\n",
        "  conv7=keras.layers.LeakyReLU(alpha=0.2,name='conv7_1_relu')(conv7)\n",
        "  #conv7 = slim.conv2d(conv7, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv7_2')\n",
        "  conv7=keras.layers.Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',name='conv7_2')(conv7)\n",
        "  conv7=keras.layers.LeakyReLU(alpha=0.2,name='conv7_2_relu')(conv7)\n",
        "\n",
        "  #up8 = upsample_and_concat(conv7, conv2, 64, 128)\n",
        "  up8=keras.layers.core.Lambda(upsample_and_concat,arguments={'x2':conv2,'output_channels':64,'in_channels':128,'layer':'upsample_concat_3'},name='upsample_concat_3')(conv7)\n",
        "  #conv8 = slim.conv2d(up8, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv8_1')\n",
        "  conv8=keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',name='conv8_1')(up8)\n",
        "  conv8=keras.layers.LeakyReLU(alpha=0.2,name='conv8_1_relu')(conv8)\n",
        "  #conv8 = slim.conv2d(conv8, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv8_2')\n",
        "  conv8=keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',name='conv8_2')(conv8)\n",
        "  conv8=keras.layers.LeakyReLU(alpha=0.2,name='conv8_2_relu')(conv8)\n",
        "\n",
        "  #up9 = upsample_and_concat(conv8, conv1, 32, 64)\n",
        "  up9=keras.layers.core.Lambda(upsample_and_concat,arguments={'x2':conv1,'output_channels':32,'in_channels':64,'layer':'upsample_concat_4'},name='upsample_concat_4')(conv8)\n",
        "  #conv9 = slim.conv2d(up9, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv9_1')\n",
        "  conv9=keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same',name='conv9_1')(up9)\n",
        "  conv9=keras.layers.LeakyReLU(alpha=0.2,name='conv9_1_relu')(conv9)\n",
        "  #conv9 = slim.conv2d(conv9, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv9_2')\n",
        "  conv9=keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same',name='conv9_2')(conv9)\n",
        "  conv9=keras.layers.LeakyReLU(alpha=0.2,name='conv9_2_relu')(conv9)\n",
        "  print(\"conv9 shape:\",conv9.shape)\n",
        "\n",
        "  #conv10 = slim.conv2d(conv9, 12, [1, 1], rate=1, activation_fn=None, scope='g_conv10')\n",
        "  conv10=keras.layers.Conv2D(filters=12,kernel_size=(1,1),strides=(1,1),name='conv10')(conv9)\n",
        "  print(\"conv10 shape:\",conv10.shape)\n",
        "  #no activation function for this last layer\n",
        "\n",
        "  predictions = keras.layers.core.Lambda(Depth_to_space_tf,name='depth_to_space')(conv10)\n",
        "  model = keras.models.Model(inputs=inputs, outputs=predictions)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8DyCh5GyNEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pack_raw(raw):\n",
        "    # pack Bayer image to 4 channels\n",
        "    im = raw.raw_image_visible.astype(np.float32)\n",
        "    #print(\"im shape:\",im.shape)\n",
        "    #print(\"im:\")\n",
        "    #print(im)\n",
        "    im = np.maximum(im - 512, 0) / (16383 - 512)  # subtract the black level and normalise with 16383 \n",
        "    ##\n",
        "    # Seems 16383 is the max value due to a 14 bit depth. can be replaced with \n",
        "    ##\n",
        "    #print(\"after normalisation\")\n",
        "    #print(im)\n",
        "\n",
        "    im = np.expand_dims(im, axis=2)\n",
        "    img_shape = im.shape\n",
        "    H = img_shape[0]\n",
        "    W = img_shape[1]\n",
        "    #print(\"after expand dims:%s ,H:%d ,W:%d \" % (img_shape,H,W))\n",
        "\n",
        "    ###\n",
        "    # single bayer pixel format:\n",
        "    # 0:R 1:G\n",
        "    # 2:G 3:B\n",
        "    ###\n",
        "    out = np.concatenate((im[0:H:2, 0:W:2, :], # get the 0th Red as per above format\n",
        "                          im[0:H:2, 1:W:2, :], # get the 1st Green\n",
        "                          im[1:H:2, 1:W:2, :], # get the 2nd Green\n",
        "                          im[1:H:2, 0:W:2, :]), axis=2) # get the 3rd Green\n",
        "    #print(\"out.shape:\",out.shape)\n",
        "    #print(out)\n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6698Y7izIn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sess = tf.Session()\n",
        "# in_image = tf.placeholder(tf.float32, [None, None, None, 4])\n",
        "# gt_image = tf.placeholder(tf.float32, [None, None, None, 3])\n",
        "#out_image = network(in_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXBqHKjN0NB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#G_loss = tf.reduce_mean(tf.abs(out_image - gt_image))\n",
        "# t_vars = tf.trainable_variables()\n",
        "#lr = tf.placeholder(tf.float32)\n",
        "#G_opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(G_loss)\n",
        "#saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75AcCZyH0XXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
        "#if ckpt:\n",
        "#    print('loaded ' + ckpt.model_checkpoint_path)\n",
        "#    saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "###\n",
        "# above commented as not needed can be uncommented\n",
        "###\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjDLxAdO0zds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gt_images = [None] * 6000\n",
        "# input_images = {}\n",
        "# input_images['300'] = [None] * len(train_ids)\n",
        "# input_images['250'] = [None] * len(train_ids)\n",
        "# input_images['100'] = [None] * len(train_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_0TfaMn3xFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#? g_loss = np.zeros((5000, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poYFXTqz5G6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# allfolders = glob.glob('./result/*0')\n",
        "# lastepoch = 0\n",
        "# for folder in allfolders:\n",
        "#     lastepoch = np.maximum(lastepoch, int(folder[-4:]))\n",
        "    \n",
        "###\n",
        "# The above code is used to infer the last completed epoch\n",
        "# ( may be in case a previously saved model is restored)\n",
        "###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaoFTFE05usd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learning_rate = 0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArFQgX5BmH9V",
        "colab_type": "code",
        "outputId": "0bc66736-8f89-4601-a676-c23e6dedaf42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_ids[0:10]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[90, 91, 92, 72, 73, 75, 76, 78, 81, 83]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icTY4imvYh2k",
        "colab_type": "code",
        "outputId": "2be086ef-456c-4830-ca73-bba8636893b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(train_ids)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "161"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkPgT9DWxYhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_id = 1\n",
        "# in_files = glob.glob(input_dir + '%05d_00*.ARW' % train_id) # get all the images path with pattern 0*train_id\n",
        "# #print(in_files)\n",
        "# in_path = in_files[np.random.randint(0, len(in_files))] # get any one image randomly\n",
        "# #print(in_path)\n",
        "# in_fn = os.path.basename(in_path) # get only the full image name\n",
        "# #print(in_fn)\n",
        "\n",
        "# gt_files = glob.glob(gt_dir + '%05d_00*.ARW' % train_id) # get the ground truth image path(s) (only 1 may exist. hence select [0]th below)\n",
        "# #print(gt_files)\n",
        "# gt_path = gt_files[0] # get the first one (as only 1 gt image should exist)\n",
        "# #print(gt_path)\n",
        "# gt_fn = os.path.basename(gt_path) # get only the full image name for gt image\n",
        "# #print(gt_fn)\n",
        "# in_exposure = float(in_fn[9:-5]) # get the exposure for input image\n",
        "# #print(in_exposure)\n",
        "# gt_exposure = float(gt_fn[9:-5]) # get the exposure for gt image\n",
        "# #print(gt_exposure)\n",
        "# ratio = min(gt_exposure / in_exposure, 300)\n",
        "# print(\"ratio:\",ratio)\n",
        "# ########################\n",
        "# gt_raw = rawpy.imread('/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/long/00001_00_10s.ARW')\n",
        "# print(gt_raw.raw_pattern)\n",
        "# print(gt_raw)\n",
        "# im = gt_raw.postprocess(use_camera_wb=True,\n",
        "#                         half_size=False,\n",
        "#                         no_auto_bright=True, output_bps=16)\n",
        "# print(im.shape)\n",
        "# print(im[0:2,:,:])\n",
        "# gt_images = np.expand_dims(np.float32(im / 65535.0),\n",
        "#         axis=0)\n",
        "# print(\"gt_image shape\",gt_images.shape)\n",
        "# print(gt_images[:,0:2,:,:])\n",
        "# ############################\n",
        "# raw = rawpy.imread('/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/short/00001_00_0.04s.ARW')\n",
        "# packed_input_image=pack_raw(raw)\n",
        "# input_img = np.expand_dims(packed_input_image, axis=0) * ratio\n",
        "# print(\"input_image shape\",input_img.shape)\n",
        "# print(input_img[:,0:2,:,:])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVcN0RNdVzAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "  \"\"\"Class to continously load images\"\"\"\n",
        "  \n",
        "  def __init__(self,epochs):\n",
        "    shutil.rmtree('/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/result_Sony', ignore_errors=True, onerror=None)\n",
        "    self.input_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/short/'\n",
        "    self.gt_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/long/'\n",
        "    os.mkdir('/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/result_Sony')\n",
        "    self.checkpoint_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/result_Sony'\n",
        "    self.result_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/result_Sony'\n",
        "    self.save_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/save_Sony'\n",
        "    if os.path.exists(self.save_dir):\n",
        "      pass\n",
        "    else:\n",
        "      os.mkdir('/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/save_Sony')\n",
        "    \n",
        "    \n",
        "    self.epochs=epochs\n",
        "    self.ps=512 # batch/patch size for images for training\n",
        "    self.learning_rate=0.0001 # not used in keras\n",
        "    \n",
        "    self.train_fns = glob.glob(gt_dir + '0*.ARW')\n",
        "    \"\"\" 0* is for Training images. 1 for Test and 2 for Validation \"\"\"\n",
        "    self.train_ids = [int(os.path.basename(train_fn)[0:5]) for train_fn in self.train_fns]\n",
        "    print(\"Total Train Ids:\",len(self.train_ids))\n",
        "    print(\"Sample Train Ids:\",self.train_ids[0:10])\n",
        "    \n",
        "    self.valid_fns = glob.glob(gt_dir + '2*.ARW')\n",
        "    \"\"\" 0* is for Training images. 1 for Test and 2 for Validation \"\"\"\n",
        "    self.valid_ids = [int(os.path.basename(valid_fn)[0:5]) for valid_fn in self.valid_fns]\n",
        "    print(\"Total Validation Ids:\",len(self.valid_ids))\n",
        "    print(\"Sample Validation Ids:\",self.valid_ids[0:10])\n",
        "    \n",
        "#     self.gt_images = [None] * 6000\n",
        "#     self.input_images = {}\n",
        "#     self.input_images['300'] = [None] * len(train_ids)\n",
        "#     self.input_images['250'] = [None] * len(train_ids)\n",
        "#     self.input_images['100'] = [None] * len(train_ids)\n",
        "    \n",
        "  def train_images_generator(self):\n",
        "    for epoch in range(0, self.epochs):\n",
        "      print(\"Current Epoch:\",epoch)\n",
        "      #if os.path.isdir('result/%04d' % epoch):\n",
        "      #  continue\n",
        "      ###\n",
        "      # used for skipping the current epoch if the checkpoint directory exists\n",
        "      ###\n",
        "      #cnt = 0\n",
        "      #if epoch > 2000: \"\"\"Learning rate not specified in keras model\"\"\"\n",
        "      #  learning_rate = 1e-5\n",
        "\n",
        "      for ind in np.random.permutation(len(self.train_ids)):\n",
        "\n",
        "        # get the path from image id\n",
        "\n",
        "        #print(\"provided image with id:\",ind)\n",
        "        train_id = self.train_ids[ind]\n",
        "        in_files = glob.glob(self.input_dir + '%05d_00*.ARW' % train_id) # get all the images path with pattern 0*train_id\n",
        "        in_path = in_files[np.random.randint(0, len(in_files))] # get any one image randomly\n",
        "        in_fn = os.path.basename(in_path) # get only the full image name\n",
        "\n",
        "        gt_files = glob.glob(self.gt_dir + '%05d_00*.ARW' % train_id) # get the ground truth image path(s) (only 1 may exist. hence select [0]th below)\n",
        "        gt_path = gt_files[0] # get the first one (as only 1 gt image should exist)\n",
        "        gt_fn = os.path.basename(gt_path) # get only the full image name for gt image\n",
        "        in_exposure = float(in_fn[9:-5]) # get the exposure for input image\n",
        "        gt_exposure = float(gt_fn[9:-5]) # get the exposure for gt image\n",
        "        ratio = min(gt_exposure / in_exposure, 300) # get the amplification ratio\n",
        "\n",
        "        st = time.time()\n",
        "        #cnt += 1\n",
        "\n",
        "        #if input_images[str(ratio)[0:3]][ind] is None: # if image is not loaded (first epoch), load it\n",
        "        raw = rawpy.imread(in_path)\n",
        "        input_images = np.expand_dims(pack_raw(raw), axis=0) * ratio # pack the bayer image in 4 channels of RGBG\n",
        "\n",
        "        gt_raw = rawpy.imread(gt_path)\n",
        "        im = gt_raw.postprocess(use_camera_wb=True,\n",
        "                      half_size=False,\n",
        "                      no_auto_bright=True, output_bps=16)\n",
        "        gt_images = np.expand_dims(np.float32(im / 65535.0),axis=0) # divide by 65535 to normalise (scale between 0 and 1)\n",
        "\n",
        "        # crop\n",
        "\n",
        "        H = input_images.shape[1] # get the image height (number of rows)\n",
        "        W = input_images.shape[2] # get the image width (number of columns)\n",
        "\n",
        "        xx = np.random.randint(0, W - self.ps) # get a random number in W-ps (W-512)\n",
        "        yy = np.random.randint(0, H - self.ps) # get a random number in H-ps (H-512)\n",
        "        input_patch = input_images[:, yy:yy + self.ps, xx:xx + self.ps, :]\n",
        "        gt_patch = gt_images[:, yy * 2:yy * 2 + self.ps * 2, xx * 2:xx * 2 + self.ps * 2, :]\n",
        "\n",
        "        if np.random.randint(2) == 1:  # random flip for rows\n",
        "          input_patch = np.flip(input_patch, axis=1)\n",
        "          gt_patch = np.flip(gt_patch, axis=1)\n",
        "        if np.random.randint(2) == 1:  # random flip for columns\n",
        "          input_patch = np.flip(input_patch, axis=2)\n",
        "          gt_patch = np.flip(gt_patch, axis=2)\n",
        "        if np.random.randint(2) == 1:  # random transpose\n",
        "          input_patch = np.transpose(input_patch, (0, 2, 1, 3))\n",
        "          gt_patch = np.transpose(gt_patch, (0, 2, 1, 3))\\\n",
        "\n",
        "        input_patch = np.minimum(input_patch, 1.0)\n",
        "\n",
        "        yield (input_patch,gt_patch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YECuKfSCS7JW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_generator(model,data_gen,epochs,steps_per_epoch,data):\n",
        "  print(\"Model Training started!!! Jay Yogeshwar!!!\")\n",
        "  save_fname = os.path.join(data.save_dir, '%s-e%s.h5' % (dt.datetime.now().strftime('%d%m%Y-%H%M%S'), str(epochs)))\n",
        "  accHistory = AccuracyHistory()\n",
        "  callbacks = [\n",
        "    ModelCheckpoint(filepath=save_fname, monitor='loss', save_best_only=True)\n",
        "  ]\n",
        "  model_history=model.fit_generator(\n",
        "      generator=data_gen,\n",
        "      steps_per_epoch=steps_per_epoch,\n",
        "      epochs=epochs,\n",
        "      callbacks=callbacks,\n",
        "      max_queue_size=50,\n",
        "      workers=30\n",
        "  )\n",
        "  print(\"Model Training completed!!! Jay Yogeshwar!!!\")\n",
        "  return model_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvdY4QQSpiKq",
        "colab_type": "code",
        "outputId": "b9e0875a-6971-48a8-db21-f280fc3cb228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 908
        }
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "  recall = true_positives / (possible_positives + K.epsilon())\n",
        "  return recall\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "  precision = true_positives / (predicted_positives + K.epsilon())\n",
        "  return precision\n",
        "\n",
        "def reduced_mean(y_true,y_pred):\n",
        "  return tf.reduce_mean(tf.abs(y_pred - y_true))\n",
        "\n",
        "data = DataLoader(4001)\n",
        "model=build_model()\n",
        "with open('model_summary.txt','w') as fh:\n",
        "    # Pass the file handle in as a lambda function to make it callable\n",
        "    model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
        "keras.utils.vis_utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "model.compile(optimizer='adam',loss=reduced_mean,metrics=['accuracy'])\n",
        "steps_per_epoch=len(data.train_ids)\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Train Ids: 161\n",
            "Sample Train Ids: [90, 91, 92, 72, 73, 75, 76, 78, 81, 83]\n",
            "Total Validation Ids: 20\n",
            "Sample Validation Ids: [20079, 20080, 20089, 20107, 20115, 20120, 20147, 20153, 20177, 20005]\n",
            "conv1 shape: (?, 512, 512, 32)\n",
            "conv1 shape: (?, 512, 512, 32)\n",
            "conv1 shape after pool: (?, 256, 256, 32)\n",
            "layer: upsample_concat_1\n",
            "x1 shape: (?, 32, 32, 512)\n",
            "x2 shape: (?, 64, 64, 256)\n",
            "deconvtf shape: (?, 64, 64, 256)\n",
            "deconv_output shape: (?, 64, 64, 512)\n",
            "layer: upsample_concat_1\n",
            "x1 shape: (?, 32, 32, 512)\n",
            "x2 shape: (?, 64, 64, 256)\n",
            "deconvtf shape: (?, 64, 64, 256)\n",
            "deconv_output shape: (?, 64, 64, 512)\n",
            "layer: upsample_concat_2\n",
            "x1 shape: (?, 64, 64, 256)\n",
            "x2 shape: (?, 128, 128, 128)\n",
            "deconvtf shape: (?, 128, 128, 128)\n",
            "deconv_output shape: (?, 128, 128, 256)\n",
            "layer: upsample_concat_2\n",
            "x1 shape: (?, 64, 64, 256)\n",
            "x2 shape: (?, 128, 128, 128)\n",
            "deconvtf shape: (?, 128, 128, 128)\n",
            "deconv_output shape: (?, 128, 128, 256)\n",
            "layer: upsample_concat_3\n",
            "x1 shape: (?, 128, 128, 128)\n",
            "x2 shape: (?, 256, 256, 64)\n",
            "deconvtf shape: (?, 256, 256, 64)\n",
            "deconv_output shape: (?, 256, 256, 128)\n",
            "layer: upsample_concat_3\n",
            "x1 shape: (?, 128, 128, 128)\n",
            "x2 shape: (?, 256, 256, 64)\n",
            "deconvtf shape: (?, 256, 256, 64)\n",
            "deconv_output shape: (?, 256, 256, 128)\n",
            "layer: upsample_concat_4\n",
            "x1 shape: (?, 256, 256, 64)\n",
            "x2 shape: (?, 512, 512, 32)\n",
            "deconvtf shape: (?, 512, 512, 32)\n",
            "deconv_output shape: (?, 512, 512, 64)\n",
            "layer: upsample_concat_4\n",
            "x1 shape: (?, 256, 256, 64)\n",
            "x2 shape: (?, 512, 512, 32)\n",
            "deconvtf shape: (?, 512, 512, 32)\n",
            "deconv_output shape: (?, 512, 512, 64)\n",
            "conv9 shape: (?, 512, 512, 32)\n",
            "conv10 shape: (?, 512, 512, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ8IR20yraX8",
        "colab_type": "code",
        "outputId": "b5f39e2d-61d9-4af6-a67c-af4ccd2a6b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "source": [
        "\"\"\" ================ TRAIN THE MODEL ================ \"\"\"\n",
        "model_history=train_generator(model,data.train_images_generator(),data.epochs,steps_per_epoch,data)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Training started!!! Jay Yogeshwar!!!\n",
            "Epoch 1/4001\n",
            "Current Epoch: 0\n",
            "  4/161 [..............................] - ETA: 16:23 - loss: 0.2837 - acc: 0.1692 - precision: 0.5229 - recall: 0.0612"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (1.165339). Check your callbacks.\n",
            "  % delta_t_median)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  5/161 [..............................] - ETA: 14:13 - loss: 0.2628 - acc: 0.1740 - precision: 0.4734 - recall: 0.0637"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.310985). Check your callbacks.\n",
            "  % delta_t_median)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  8/161 [>.............................] - ETA: 9:58 - loss: 0.2249 - acc: 0.2004 - precision: 0.3414 - recall: 0.1092 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.344716). Check your callbacks.\n",
            "  % delta_t_median)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 12/161 [=>............................] - ETA: 8:55 - loss: 0.1819 - acc: 0.2601 - precision: 0.3191 - recall: 0.1327"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-f3e38eba7047>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\" ================ TRAIN THE MODEL ================ \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_images_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-104-a2ac5a3a29a9>\u001b[0m in \u001b[0;36mtrain_generator\u001b[0;34m(model, data_gen, epochs, steps_per_epoch, data)\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m       \u001b[0;31m#max_queue_size=50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0;31m#workers=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6rt0FGT6jY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for epoch in range(lastepoch, 4001):\n",
        "#     #if os.path.isdir('result/%04d' % epoch):\n",
        "#     #    continue\n",
        "#     ###\n",
        "#     # used for skipping the current epoch if the checkpoint directory exists\n",
        "#     ###\n",
        "#     cnt = 0\n",
        "#     if epoch > 2000:\n",
        "#         learning_rate = 1e-5\n",
        "\n",
        "#     for ind in np.random.permutation(len(train_ids)):\n",
        "\n",
        "#         # get the path from image id\n",
        "\n",
        "#         train_id = train_ids[ind]\n",
        "#         in_files = glob.glob(input_dir + '%05d_00*.ARW' % train_id) # get all the images path with pattern 0*train_id\n",
        "#         in_path = in_files[np.random.randint(0, len(in_files))] # get any one image randomly\n",
        "#         in_fn = os.path.basename(in_path) # get only the full image name\n",
        "\n",
        "#         gt_files = glob.glob(gt_dir + '%05d_00*.ARW' % train_id) # get the ground truth image path(s) (only 1 may exist. hence select [0]th below)\n",
        "#         gt_path = gt_files[0] # get the first one (as only 1 gt image should exist)\n",
        "#         gt_fn = os.path.basename(gt_path) # get only the full image name for gt image\n",
        "#         in_exposure = float(in_fn[9:-5]) # get the exposure for input image\n",
        "#         gt_exposure = float(gt_fn[9:-5]) # get the exposure for gt image\n",
        "#         ratio = min(gt_exposure / in_exposure, 300) # get the amplification ratio\n",
        "\n",
        "#         st = time.time()\n",
        "#         cnt += 1\n",
        "\n",
        "#         if input_images[str(ratio)[0:3]][ind] is None: # if image is not loaded (first epoch), load it\n",
        "#             raw = rawpy.imread(in_path)\n",
        "#             input_images[str(ratio)[0:3]][ind] = \\\n",
        "#                 np.expand_dims(pack_raw(raw), axis=0) * ratio # pack the bayer image in 4 channels of RGBG\n",
        "\n",
        "#             gt_raw = rawpy.imread(gt_path)\n",
        "#             im = gt_raw.postprocess(use_camera_wb=True,\n",
        "#                                     half_size=False,\n",
        "#                                     no_auto_bright=True, output_bps=16)\n",
        "#             gt_images[ind] = np.expand_dims(np.float32(im / 65535.0),axis=0) # divide by 65535 to normalise (scale between 0 and 1)\n",
        "\n",
        "#         # crop\n",
        "\n",
        "#         H = input_images[str(ratio)[0:3]][ind].shape[1] # get the image height (number of rows)\n",
        "#         W = input_images[str(ratio)[0:3]][ind].shape[2] # get the image width (number of columns)\n",
        "\n",
        "#         xx = np.random.randint(0, W - ps) # get a random number in W-ps (W-512)\n",
        "#         yy = np.random.randint(0, H - ps) # get a random number in H-ps (H-512)\n",
        "#         input_patch = input_images[str(ratio)[0:3]][ind][:, yy:yy + ps,\n",
        "#                 xx:xx + ps, :]\n",
        "#         gt_patch = gt_images[ind][:, yy * 2:yy * 2 + ps * 2, xx * 2:xx\n",
        "#                                   * 2 + ps * 2, :]\n",
        "\n",
        "#         if np.random.randint(2) == 1:  # random flip for rows\n",
        "#             input_patch = np.flip(input_patch, axis=1)\n",
        "#             gt_patch = np.flip(gt_patch, axis=1)\n",
        "#         if np.random.randint(2) == 1:  # random flip for columns\n",
        "#             input_patch = np.flip(input_patch, axis=2)\n",
        "#             gt_patch = np.flip(gt_patch, axis=2)\n",
        "#         if np.random.randint(2) == 1:  # random transpose\n",
        "#             input_patch = np.transpose(input_patch, (0, 2, 1, 3))\n",
        "#             gt_patch = np.transpose(gt_patch, (0, 2, 1, 3))\\\n",
        "\n",
        "#         input_patch = np.minimum(input_patch, 1.0)\n",
        "\n",
        "#         (_, G_current, output) = sess.run([G_opt, G_loss, out_image],\n",
        "#                 feed_dict={in_image: input_patch, gt_image: gt_patch,\n",
        "#                 lr: learning_rate})\n",
        "#         output = np.minimum(np.maximum(output, 0), 1)\n",
        "#         g_loss[ind] = G_current\n",
        "\n",
        "#         print '%d %d Loss=%.3f Time=%.3f' % (epoch, cnt,\n",
        "#                 np.mean(g_loss[np.where(g_loss)]), time.time() - st)\n",
        "\n",
        "#         if epoch % save_freq == 0:\n",
        "#             if not os.path.isdir(result_dir + '%04d' % epoch):\n",
        "#                 os.makedirs(result_dir + '%04d' % epoch)\n",
        "\n",
        "#             temp = np.concatenate((gt_patch[0, :, :, :], output[0, :, :\n",
        "#                                   , :]), axis=1)\n",
        "#             scipy.misc.toimage(temp * 255, high=255, low=0, cmin=0,\n",
        "#                                cmax=255).save(result_dir\n",
        "#                     + '%04d/%05d_00_train_%d.jpg' % (epoch, train_id,\n",
        "#                     ratio))\n",
        "\n",
        "#     saver.save(sess, checkpoint_dir + 'model.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir4Xcjn_mfhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}