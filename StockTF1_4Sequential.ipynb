{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StockTF1_4Sequential.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KashyapCKotak/AI-ML-experiments/blob/master/StockTF1_4Sequential.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKhqP9S5hcLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class DataLoader():\n",
        "    \"\"\"A class for loading and transforming data for the lstm model\"\"\"\n",
        "\n",
        "    def __init__(self, filename, split, cols):\n",
        "        dataframe = pd.read_csv(filename)\n",
        "        print(\"data shape:\",dataframe.shape)\n",
        "        i_split = int(len(dataframe) * split)\n",
        "        self.data_train = dataframe.get(cols).values[:i_split]\n",
        "        self.data_test  = dataframe.get(cols).values[i_split:]\n",
        "        self.len_train  = len(self.data_train)\n",
        "        self.len_test   = len(self.data_test)\n",
        "        self.len_train_windows = None\n",
        "\n",
        "    def get_test_data(self, seq_len, normalise):\n",
        "        '''\n",
        "        Create x, y test data windows\n",
        "        Warning: batch method, not generative, make sure you have enough memory to\n",
        "        load data, otherwise reduce size of the training split.\n",
        "        '''\n",
        "        data_windows = []\n",
        "        for i in range(self.len_test - seq_len):\n",
        "            data_windows.append(self.data_test[i:i+seq_len])\n",
        "\n",
        "        data_windows = np.array(data_windows).astype(float)\n",
        "        data_windows = self.normalise_windows(data_windows, single_window=False) if normalise else data_windows\n",
        "\n",
        "        x = data_windows[:, :-1]\n",
        "        y = data_windows[:, -1, [0]]\n",
        "        return x,y\n",
        "\n",
        "    def get_train_data(self, seq_len, normalise):\n",
        "        '''\n",
        "        Create x, y train data windows\n",
        "        Warning: batch method, not generative, make sure you have enough memory to\n",
        "        load data, otherwise use generate_training_window() method.\n",
        "        '''\n",
        "        data_x = []\n",
        "        data_y = []\n",
        "        for i in range(self.len_train - seq_len):\n",
        "            x, y = self._next_window(i, seq_len, normalise)\n",
        "            data_x.append(x)\n",
        "            data_y.append(y)\n",
        "        return np.array(data_x), np.array(data_y)\n",
        "\n",
        "    def generate_train_batch(self, seq_len, batch_size, normalise):\n",
        "        '''Yield a generator of training data from filename on given list of cols split for train/test'''\n",
        "        i = 0\n",
        "        while i < (self.len_train - seq_len):\n",
        "            x_batch = []\n",
        "            y_batch = []\n",
        "            for b in range(batch_size):\n",
        "                if i >= (self.len_train - seq_len):\n",
        "                    # stop-condition for a smaller final batch if data doesn't divide evenly\n",
        "                    yield np.array(x_batch), np.array(y_batch)\n",
        "                    i = 0\n",
        "                x, y = self._next_window(i, seq_len, normalise)\n",
        "                x_batch.append(x)\n",
        "                y_batch.append(y)\n",
        "                i += 1\n",
        "            yield np.array(x_batch), np.array(y_batch)\n",
        "\n",
        "    def _next_window(self, i, seq_len, normalise):\n",
        "        '''Generates the next data window from the given index location i'''\n",
        "        window = self.data_train[i:i+seq_len]\n",
        "        window = self.normalise_windows(window, single_window=True)[0] if normalise else window\n",
        "        x = window[:-1]\n",
        "        y = window[-1, [0]]\n",
        "        return x, y\n",
        "\n",
        "    def normalise_windows(self, window_data, single_window=False):\n",
        "        '''Normalise window with a base value of zero'''\n",
        "        normalised_data = []\n",
        "        window_data = [window_data] if single_window else window_data\n",
        "        for window in window_data:\n",
        "            normalised_window = []\n",
        "            for col_i in range(window.shape[1]):\n",
        "                normalised_col = [((float(p) / float(window[0, col_i])) - 1) for p in window[:, col_i]]\n",
        "                normalised_window.append(normalised_col)\n",
        "            normalised_window = np.array(normalised_window).T # reshape and transpose array back into original multidimensional format\n",
        "            normalised_data.append(normalised_window)\n",
        "        return np.array(normalised_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiwmP6WoieLm",
        "colab_type": "code",
        "outputId": "83fd8ec1-4bd6-4ed1-f912-cf56ed6dfdec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "filename=\"sinewave.csv\"\n",
        "columns=[\"sinewave\"]\n",
        "sequence_length=3\n",
        "train_test_split=0.8\n",
        "data = DataLoader(filename,train_test_split,columns)\n",
        "\n",
        "\n",
        "x, y = data.get_train_data(\n",
        "\tseq_len = sequence_length,\n",
        "\tnormalise = False\n",
        ")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data shape: (5001, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtNrcevo89S8",
        "colab_type": "code",
        "outputId": "ebedb760-b901-46a5-d956-c3a8862968c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "data_gen = data.generate_train_batch(\n",
        "\t\tseq_len = 3,\n",
        "\t\tbatch_size = 10,\n",
        "\t\tnormalise = False\n",
        "\t)\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "print(next(data_gen)[0].shape)\n",
        "print(next(data_gen)[1].shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3997, 2, 1)\n",
            "(3997, 1)\n",
            "(10, 2, 1)\n",
            "(10, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpKKwvhwCTJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime as dt\n",
        "\n",
        "class Timer():\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tself.start_dt = None\n",
        "\n",
        "\tdef start(self):\n",
        "\t\tself.start_dt = dt.datetime.now()\n",
        "\n",
        "\tdef stop(self):\n",
        "\t\tend_dt = dt.datetime.now()\n",
        "\t\tprint('Time taken: %s' % (end_dt - self.start_dt))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3y8XjC-t_CG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from numpy import newaxis\n",
        "from keras.layers import Dense, Activation, Dropout, LSTM\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "class Model():\n",
        "\t\"\"\"A class for an building and inferencing an lstm model\"\"\"\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tself.model = Sequential()\n",
        "\n",
        "\tdef load_model(self, filepath):\n",
        "\t\tprint('[Model] Loading model from file %s' % filepath)\n",
        "\t\tself.model = load_model(filepath)\n",
        "\n",
        "\tdef build_model(self, configs):\n",
        "\t\ttimer = Timer()\n",
        "\t\ttimer.start()\n",
        "\n",
        "\t\tfor layer in configs['model']['layers']:\n",
        "\t\t\tneurons = layer['neurons'] if 'neurons' in layer else None\n",
        "\t\t\tdropout_rate = layer['rate'] if 'rate' in layer else None\n",
        "\t\t\tactivation = layer['activation'] if 'activation' in layer else None\n",
        "\t\t\treturn_seq = layer['return_seq'] if 'return_seq' in layer else None\n",
        "\t\t\tinput_timesteps = layer['input_timesteps'] if 'input_timesteps' in layer else None\n",
        "\t\t\tinput_dim = layer['input_dim'] if 'input_dim' in layer else None\n",
        "\n",
        "\t\t\tif layer['type'] == 'dense':\n",
        "\t\t\t\tself.model.add(Dense(neurons, activation=activation))\n",
        "\t\t\tif layer['type'] == 'lstm':\n",
        "\t\t\t\tself.model.add(LSTM(neurons, input_shape=(input_timesteps, input_dim), return_sequences=return_seq))\n",
        "\t\t\tif layer['type'] == 'dropout':\n",
        "\t\t\t\tself.model.add(Dropout(dropout_rate))\n",
        "\n",
        "\t\tself.model.compile(loss=configs['model']['loss'], optimizer=configs['model']['optimizer'],metrics=['mean_squared_error'])\n",
        "\n",
        "\t\tprint('[Model] Model Compiled')\n",
        "\t\ttimer.stop()\n",
        "\n",
        "\tdef train(self, x, y, epochs, batch_size, save_dir=\"\"):\n",
        "\t\ttimer = Timer()\n",
        "\t\ttimer.start()\n",
        "\t\tprint('X shape:', (x.shape))\n",
        "\t\tprint('[Model] Training Started')\n",
        "\t\tprint('[Model] %s epochs, %s batch size' % (epochs, batch_size))\n",
        "\t\t\n",
        "\t\tsave_fname = os.path.join(save_dir, '%s-e%s.h5' % (dt.datetime.now().strftime('%d%m%Y-%H%M%S'), str(epochs)))\n",
        "\t\tcallbacks = [\n",
        "\t\t\tEarlyStopping(monitor='val_loss', patience=2),\n",
        "\t\t\tModelCheckpoint(filepath=save_fname, monitor='val_loss', save_best_only=True)\n",
        "\t\t]\n",
        "\t\tmodelhistory=self.model.fit(\n",
        "\t\t\tx,\n",
        "\t\t\ty,\n",
        "\t\t\tepochs=epochs,\n",
        "\t\t\tbatch_size=batch_size,\n",
        "\t\t\tcallbacks=callbacks\n",
        "\t\t)\n",
        "\t\tself.model.save(save_fname)\n",
        "\t\tprint('[Model] Training Completed. Model saved as %s' % save_fname)\n",
        "\t\ttimer.stop()\n",
        "\t\treturn modelhistory\n",
        "\n",
        "\tdef train_generator(self, data_gen, epochs, batch_size, steps_per_epoch, save_dir):\n",
        "\t\ttimer = Timer()\n",
        "\t\ttimer.start()\n",
        "\t\tprint('X shape:', (x.shape))\n",
        "\t\tprint('[Model] Training Started')\n",
        "\t\tprint('[Model] %s epochs, %s batch size, %s batches per epoch' % (epochs, batch_size, steps_per_epoch))\n",
        "\t\t\n",
        "\t\tsave_fname = os.path.join(save_dir, '%s-e%s.h5' % (dt.datetime.now().strftime('%d%m%Y-%H%M%S'), str(epochs)))\n",
        "\t\tcallbacks = [\n",
        "\t\t\tModelCheckpoint(filepath=save_fname, monitor='loss', save_best_only=True)\n",
        "\t\t]\n",
        "\t\tself.model.fit_generator(\n",
        "\t\t\tdata_gen,\n",
        "\t\t\tsteps_per_epoch=steps_per_epoch,\n",
        "\t\t\tepochs=epochs,\n",
        "\t\t\tcallbacks=callbacks,\n",
        "\t\t\tworkers=1\n",
        "\t\t)\n",
        "\t\t\n",
        "\t\tprint('[Model] Training Completed. Model saved as %s' % save_fname)\n",
        "\t\ttimer.stop()\n",
        "\n",
        "\tdef predict_point_by_point(self, data):\n",
        "\t\t#Predict each timestep given the last sequence of true data, in effect only predicting 1 step ahead each time\n",
        "\t\tprint('[Model] Predicting Point-by-Point...')\n",
        "\t\tpredicted = self.model.predict(data)\n",
        "\t\tpredicted = np.reshape(predicted, (predicted.size,))\n",
        "\t\treturn predicted\n",
        "\n",
        "\tdef predict_sequences_multiple(self, data, window_size, prediction_len):\n",
        "\t\t#Predict sequence of 50 steps before shifting prediction run forward by 50 steps\n",
        "\t\tprint('[Model] Predicting Sequences Multiple...')\n",
        "\t\tprediction_seqs = []\n",
        "\t\tfor i in range(int(len(data)/prediction_len)):\n",
        "\t\t\tcurr_frame = data[i*prediction_len]\n",
        "\t\t\tpredicted = []\n",
        "\t\t\tfor j in range(prediction_len):\n",
        "\t\t\t\tpredicted.append(self.model.predict(curr_frame[newaxis,:,:])[0,0])\n",
        "\t\t\t\tcurr_frame = curr_frame[1:]\n",
        "\t\t\t\tcurr_frame = np.insert(curr_frame, [window_size-2], predicted[-1], axis=0)\n",
        "\t\t\tprediction_seqs.append(predicted)\n",
        "\t\treturn prediction_seqs\n",
        "\n",
        "\tdef predict_sequence_full(self, data, window_size):\n",
        "\t\t#Shift the window by 1 new prediction each time, re-run predictions on new window\n",
        "\t\tprint('[Model] Predicting Sequences Full...')\n",
        "\t\tcurr_frame = data[0]\n",
        "\t\tpredicted = []\n",
        "\t\tfor i in range(len(data)):\n",
        "\t\t\tpredicted.append(self.model.predict(curr_frame[newaxis,:,:])[0,0])\n",
        "\t\t\tcurr_frame = curr_frame[1:]\n",
        "\t\t\tcurr_frame = np.insert(curr_frame, [window_size-2], predicted[-1], axis=0)\n",
        "\t\treturn predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTsi9WQkCX86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "configJson={\n",
        "\t\"data\": {\n",
        "\t\t\"filename\": \"sinewave.csv\",\n",
        "\t\t\"columns\": [\n",
        "\t\t\t\"sinewave\"\n",
        "\t\t],\n",
        "\t\t\"sequence_length\": 50,\n",
        "\t\t\"train_test_split\": 0.8,\n",
        "\t\t\"normalise\": False\n",
        "\t},\n",
        "\t\"training\": {\n",
        "\t\t\"epochs\": 4,\n",
        "\t\t\"batch_size\": 32\n",
        "\t},\n",
        "\t\"model\": {\n",
        "\t\t\"loss\": \"mse\",\n",
        "\t\t\"optimizer\": \"adam\",\n",
        "\t\t\"layers\": [\n",
        "\t\t\t{\n",
        "\t\t\t\t\"type\": \"lstm\",\n",
        "\t\t\t\t\"neurons\": 50,\n",
        "\t\t\t\t\"input_timesteps\": 49,\n",
        "\t\t\t\t\"input_dim\": 1,\n",
        "\t\t\t\t\"return_seq\": True\n",
        "\t\t\t},\n",
        "\t\t\t{\n",
        "\t\t\t\t\"type\": \"dropout\",\n",
        "\t\t\t\t\"rate\": 0.05\n",
        "\t\t\t},\n",
        "\t\t\t{\n",
        "\t\t\t\t\"type\": \"lstm\",\n",
        "\t\t\t\t\"neurons\": 100,\n",
        "\t\t\t\t\"return_seq\": False\n",
        "\t\t\t},\n",
        "\t\t\t{\n",
        "\t\t\t\t\"type\": \"dropout\",\n",
        "\t\t\t\t\"rate\": 0.05\n",
        "\t\t\t},\n",
        "\t\t\t{\n",
        "\t\t\t\t\"type\": \"dense\",\n",
        "\t\t\t\t\"neurons\": 1,\n",
        "\t\t\t\t\"activation\": \"linear\"\n",
        "\t\t\t}\n",
        "\t\t]\n",
        "\t}\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0cFX1_3CjR5",
        "colab_type": "code",
        "outputId": "49cbf275-b5d4-4534-d93d-f1747aca7571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "configs = configJson\n",
        "\n",
        "data = DataLoader(\n",
        "\tos.path.join(configs['data']['filename']),\n",
        "\tconfigs['data']['train_test_split'],\n",
        "\tconfigs['data']['columns']\n",
        ")\n",
        "\n",
        "model = Model()\n",
        "model.build_model(configs)\n",
        "x, y = data.get_train_data(\n",
        "\tseq_len = configs['data']['sequence_length'],\n",
        "\tnormalise = configs['data']['normalise']\n",
        ")\n",
        "\n",
        "modelhistory=model.train(\n",
        "\tx,\n",
        "\ty,\n",
        "\tepochs = configs['training']['epochs'],\n",
        "\tbatch_size = configs['training']['batch_size']\n",
        ")\n",
        "\n",
        "x_test, y_test = data.get_test_data(\n",
        "\tseq_len = configs['data']['sequence_length'],\n",
        "\tnormalise = configs['data']['normalise']\n",
        ")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data shape: (5001, 1)\n",
            "[Model] Model Compiled\n",
            "Time taken: 0:00:00.529072\n",
            "X shape: (3950, 49, 1)\n",
            "[Model] Training Started\n",
            "[Model] 7 epochs, 64 batch size\n",
            "Epoch 1/7\n",
            "3950/3950 [==============================] - 14s 4ms/step - loss: 0.0616 - mean_squared_error: 0.0616\n",
            "Epoch 2/7\n",
            "  64/3950 [..............................] - ETA: 12s - loss: 9.8032e-04 - mean_squared_error: 9.8032e-04"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mean_squared_error\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:434: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3950/3950 [==============================] - 12s 3ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 3/7\n",
            "3950/3950 [==============================] - 12s 3ms/step - loss: 9.9664e-04 - mean_squared_error: 9.9664e-04\n",
            "Epoch 4/7\n",
            "3950/3950 [==============================] - 12s 3ms/step - loss: 9.1152e-04 - mean_squared_error: 9.1152e-04\n",
            "Epoch 5/7\n",
            "3950/3950 [==============================] - 12s 3ms/step - loss: 8.1840e-04 - mean_squared_error: 8.1840e-04\n",
            "Epoch 6/7\n",
            "3950/3950 [==============================] - 12s 3ms/step - loss: 7.4672e-04 - mean_squared_error: 7.4672e-04\n",
            "Epoch 7/7\n",
            "3950/3950 [==============================] - 12s 3ms/step - loss: 8.2588e-04 - mean_squared_error: 8.2588e-04\n",
            "[Model] Training Completed. Model saved as 14072019-070941-e7.h5\n",
            "Time taken: 0:01:28.743008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p2GGmnwOB98",
        "colab_type": "code",
        "outputId": "3176fb68-0278-425a-db11-ca26cf520b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Visualize training history\n",
        "print(modelhistory.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(modelhistory.history['mean_squared_error'])\n",
        "plt.title('MSE')\n",
        "plt.ylabel('mse')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(modelhistory.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'mean_squared_error'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXbJrztH0cOQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMxuVw8LMzEblsDAzs1E5LMzMbFT/H2bdAkz5oEzDAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jK62KBkCsQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_multiseq = model.predict_sequences_multiple(x_test, configs['data']['sequence_length'], configs['data']['sequence_length'])\n",
        "predictions_fullseq = model.predict_sequence_full(x_test, configs['data']['sequence_length'])\n",
        "predictions_pointbypoint = model.predict_point_by_point(x_test)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR68zLJr_Urf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_results_multiple(predicted_data, true_data, prediction_len):\n",
        "    fig = plt.figure(facecolor='white')\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(true_data, label='True Data')\n",
        "\t# Pad the list of predictions to shift it in the graph to it's correct start\n",
        "    for i, data in enumerate(predicted_data):\n",
        "        padding = [None for p in range(i * prediction_len)]\n",
        "        plt.plot(padding + data, label='Prediction')\n",
        "        plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "def plot_results(predicted_data, true_data):\n",
        "    fig = plt.figure(facecolor='white')\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(true_data, label='True Data')\n",
        "    plt.plot(predicted_data, label='Prediction')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "plot_results_multiple(predictions_multiseq, y_test, configs['data']['sequence_length'])\n",
        "plot_results(predictions_fullseq, y_test)\n",
        "plot_results(predictions_pointbypoint, y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDWlHAf-OUx4",
        "colab_type": "text"
      },
      "source": [
        "##################################\n",
        "##################################\n",
        "\n",
        "------------------------------------------- **NOW the same for STOCKS** -------------------------------------------\n",
        "\n",
        "##################################\n",
        "##################################\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyUoD6YM_ZKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "{\n",
        "\t\"data\": {\n",
        "\t\t\"filename\": \"sp500.csv\",\n",
        "\t\t\"columns\": [\n",
        "\t\t\t\"Close\"\n",
        "\t\t],\n",
        "\t\t\"sequence_length\": 50,\n",
        "\t\t\"train_test_split\": 0.85,\n",
        "\t\t\"normalise\": True\n",
        "\t},\n",
        "\t\"training\": {\n",
        "\t\t\"epochs\": 1,\n",
        "\t\t\"batch_size\": 32\n",
        "\t},\n",
        "\t\"model\": {\n",
        "\t\t\"loss\": \"mse\",\n",
        "\t\t\"optimizer\": \"adam\",\n",
        "\t\t\"layers\": [\n",
        "\t\t\t{\n",
        "\t\t\t\t\"type\": \"lstm\",\n",
        "\t\t\t\t\"neurons\": 100,\n",
        "\t\t\t\t\"input_timesteps\": 49,\n",
        "\t\t\t\t\"input_dim\": 1,\n",
        "\t\t\t\t\"return_seq\": True\n",
        "\t\t\t},\n",
        "\t\t\t{\n",
        "\t\t\t\t\"type\": \"dropout\",\n",
        "\t\t\t\t\"rate\": 0.2\n",
        "\t\t\t},\n",
        "\t\t\t{\n",
        "\t\t\t\t\"type\": \"lstm\",\n",
        "\t\t\t\t\"neurons\": 100,\n",
        "\t\t\t\t\"return_seq\": True\n",
        "\t\t\t},\n",
        "\t\t\t{\n",
        "\t\t\t\t\"type\": \"lstm\",\n",
        "\t\t\t\t\"neurons\": 100,\n",
        "\t\t\t\t\"return_seq\": False\n",
        "\t\t\t},\n",
        "\t\t\t{\n",
        "\t\t\t\t\"type\": \"dropout\",\n",
        "\t\t\t\t\"rate\": 0.2\n",
        "\t\t\t},\n",
        "\t\t\t{\n",
        "\t\t\t\t\"type\": \"dense\",\n",
        "\t\t\t\t\"neurons\": 1,\n",
        "\t\t\t\t\"activation\": \"linear\"\n",
        "\t\t\t}\n",
        "\t\t]\n",
        "\t}\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAn6JbWmQvoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "configs = json.load(open('config.json', 'r'))\n",
        "\n",
        "data = DataLoader(\n",
        "\tos.path.join('data', configs['data']['filename']),\n",
        "\tconfigs['data']['train_test_split'],\n",
        "\tconfigs['data']['columns']\n",
        ")\n",
        "\n",
        "model = Model()\n",
        "model.build_model(configs)\n",
        "\n",
        "# out-of memory generative training\n",
        "steps_per_epoch = math.ceil((data.len_train - configs['data']['sequence_length']) / configs['training']['batch_size'])\n",
        "model.train_generator(\n",
        "\tdata_gen = data.generate_train_batch(\n",
        "\t\tseq_len = configs['data']['sequence_length'],\n",
        "\t\tbatch_size = configs['training']['batch_size'],\n",
        "\t\tnormalise = configs['data']['normalise']\n",
        "\t),\n",
        "\tepochs = configs['training']['epochs'],\n",
        "\tbatch_size = configs['training']['batch_size'],\n",
        "\tsteps_per_epoch = steps_per_epoch\n",
        ")\n",
        "\n",
        "x_test, y_test = data.get_test_data(\n",
        "\tseq_len = configs['data']['sequence_length'],\n",
        "\tnormalise = configs['data']['normalise']\n",
        ")\n",
        "\n",
        "predictions_multiseq = model.predict_sequences_multiple(x_test, configs['data']['sequence_length'], configs['data']['sequence_length'])\n",
        "predictions_fullseq = model.predict_sequence_full(x_test, configs['data']['sequence_length'])\n",
        "predictions_pointbypoint = model.predict_point_by_point(x_test)        \n",
        "\n",
        "plot_results_multiple(predictions_multiseq, y_test, configs['data']['sequence_length'])\n",
        "plot_results(predictions_fullseq, y_test)\n",
        "plot_results(predictions_pointbypoint, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au29QU9YVT3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}