{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SeeInDark_Keras_Tensorflow_Sequence.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KashyapCKotak/AI-ML-experiments/blob/master/SeeInDark_Keras_Tensorflow_Sequence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuMNVBqt0u-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import requests\n",
        "# import os\n",
        "\n",
        "# def download_file_from_google_drive(id, destination):\n",
        "#     URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "#     session = requests.Session()\n",
        "\n",
        "#     response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "#     token = get_confirm_token(response)\n",
        "\n",
        "#     if token:\n",
        "#         params = { 'id' : id, 'confirm' : token }\n",
        "#         response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "#     save_response_content(response, destination)    \n",
        "\n",
        "# def get_confirm_token(response):\n",
        "#     for key, value in response.cookies.items():\n",
        "#         if key.startswith('download_warning'):\n",
        "#             return value\n",
        "\n",
        "#     return None\n",
        "\n",
        "# def save_response_content(response, destination):\n",
        "#     CHUNK_SIZE = 32768\n",
        "\n",
        "#     with open(destination, \"wb\") as f:\n",
        "#         for chunk in response.iter_content(CHUNK_SIZE):\n",
        "#             if chunk: # filter out keep-alive new chunks\n",
        "#                 f.write(chunk)\n",
        "\n",
        "\n",
        "\n",
        "# print('Dowloading Sony subset... (25GB)')\n",
        "# download_file_from_google_drive('10kpAcvldtcb9G2ze5hTcF1odzu4V_Zvh', './Sony.zip')\n",
        "\n",
        "# #print('Dowloading Fuji subset... (52GB)')\n",
        "# #download_file_from_google_drive('12hvKCjwuilKTZPe9EZ7ZTb-azOmUA3HT', 'dataset/Fuji.zip')\n",
        "\n",
        "# os.system('unzip ./Sony.zip -d dataset')\n",
        "# #os.system('unzip dataset/Fuji.zip -d dataset')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsP1lrRN-HPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import shutil\n",
        "# shutil.rmtree('result_Sony', ignore_errors=True, onerror=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-_85I6g3eA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# os.system('unzip ./Sony.zip -d dataset')\n",
        "#os.system('unzip dataset/Fuji.zip -d dataset')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDQVxKF8nooG",
        "colab_type": "code",
        "outputId": "43a086dc-8f0d-4941-a3a9-d11549c80ecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9yF04nOlUCP",
        "colab_type": "text"
      },
      "source": [
        "**Main Train Code:**\n",
        "================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_zLVCtYlfSH",
        "colab_type": "code",
        "outputId": "313a8463-1fc9-4d15-dfe4-e22527bd3ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "!pip install rawpy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rawpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/04/997062d83766f5fbfa4dc0d20180c5085b55a74e69559e9cb6d4f1e9550e/rawpy-0.13.1-cp36-cp36m-manylinux1_x86_64.whl (682kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rawpy) (1.16.4)\n",
            "Installing collected packages: rawpy\n",
            "Successfully installed rawpy-0.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IogQOu0slZNT",
        "colab_type": "code",
        "outputId": "64f798eb-5406-4a45-e0d9-b364c4cea30d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from __future__ import division\n",
        "import os, time, scipy.io\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "import numpy as np\n",
        "import rawpy\n",
        "import glob\n",
        "import keras\n",
        "import shutil\n",
        "import datetime as dt\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import threading\n",
        "import json"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gTj24DXlazJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import shutil\n",
        "# shutil.rmtree('result_Sony', ignore_errors=True, onerror=None)\n",
        "\n",
        "# input_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/short/'\n",
        "# gt_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/long/'\n",
        "# os.mkdir('result_Sony')\n",
        "# checkpoint_dir = './result_Sony/'\n",
        "# result_dir = './result_Sony/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1bgs9-jrfgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_fns = glob.glob(gt_dir + '0*.ARW')\n",
        "###\n",
        "# 0* is for Training images. 1 for Test and 2 for Validation\n",
        "###\n",
        "# train_ids = [int(os.path.basename(train_fn)[0:5]) for train_fn in train_fns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbi6fY6ZiBz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ps = 512  # just a random patch size for training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V56pWdxpiGxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save_freq = 500\n",
        "# DEBUG = 0\n",
        "# if DEBUG == 1:\n",
        "#     save_freq = 2\n",
        "#     train_ids = train_ids[0:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vexCrDNtiIrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lrelu(x): # not used. Used Kears LeakyReLU with alpha 0.2 instead\n",
        "    return tf.maximum(x * 0.2, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZkJ3o0ZiKQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" This cell contains the custom Lambda layers to be used in building the  keras mdoel \"\"\"\n",
        "def upsample_and_concat(x1,x2,output_channels,in_channels,layer):\n",
        "  print(\"layer:\",layer)\n",
        "  pool_size = 2\n",
        "  deconv_filter = tf.Variable(tf.truncated_normal([pool_size, pool_size, output_channels, in_channels], stddev=0.02))\n",
        "  print(\"x1 shape:\",x1.shape)\n",
        "  print(\"x2 shape:\",x2.shape)\n",
        "  deconvtf=tf.nn.conv2d_transpose(x1, deconv_filter, tf.shape(x2), strides=[1, pool_size, pool_size, 1])\n",
        "  print(\"deconvtf shape:\",deconvtf.shape)\n",
        "  #deconv=keras.layers.Conv2DTranspose(filters=output_channels,kernel_size=(pool_size, pool_size),strides=(pool_size, pool_size))(x1)\n",
        "  #print(\"deconvk shape:\",deconv.shape)\n",
        "\n",
        "  deconv_output = tf.concat([deconvtf, x2], 3)\n",
        "  print(\"deconv_output shape:\",deconv_output.shape)\n",
        "  deconv_output.set_shape([None, None, None, output_channels * 2])\n",
        "\n",
        "  return deconv_output\n",
        "\n",
        "def Depth_to_space_tf(input):\n",
        "  return tf.depth_to_space(input, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cRpNNVlYXKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testing code\n",
        "# t=tf.ones([1,450,350,4])\n",
        "# deconv_filter = tf.Variable(tf.truncated_normal([2, 2, 256, 512], stddev=0.02))\n",
        "# tf.nn.conv2d_transpose(t, deconv_filter, [1,450,350,], strides=[1, pool_size, pool_size, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUz7pW3dm8Qh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  inputs=keras.layers.Input(shape=(None, None, 4))\n",
        "  #definition: slim.conv2d(inputs,number of outputs, kernel shape)\n",
        "  #definition: slim.max_pool2d(inputsconv2d_transpose ,kernel_size, padding)\n",
        "  #conv1 = slim.conv2d(input, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_1')\n",
        "  conv1=keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same',name='conv1_1')(inputs)\n",
        "  conv1=keras.layers.LeakyReLU(alpha=0.2,name='conv1_1_relu')(conv1)\n",
        "  print(\"conv1 shape:\",conv1.shape)\n",
        "  #conv1 = slim.conv2d(conv1, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_2')\n",
        "  conv1=keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same',name='conv1_2')(conv1)\n",
        "  conv1=keras.layers.LeakyReLU(alpha=0.2,name='conv1_2_relu')(conv1)\n",
        "  print(\"conv1 shape:\",conv1.shape)\n",
        "  #pool1 = slim.max_pool2d(conv1, [2, 2], padding='SAME')\n",
        "  pool1=keras.layers.MaxPooling2D(pool_size=(2,2),padding=\"same\",name='pool1')(conv1)\n",
        "  print(\"conv1 shape after pool:\",pool1.shape)\n",
        "\n",
        "  #conv2 = slim.conv2d(pool1, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv2_1')\n",
        "  conv2=keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',name='conv2_1')(pool1)\n",
        "  conv2=keras.layers.LeakyReLU(alpha=0.2,name='conv2_1_relu')(conv2)\n",
        "  #conv2 = slim.conv2d(conv2, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv2_2')\n",
        "  conv2=keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',name='conv2_2')(conv2)\n",
        "  conv2=keras.layers.LeakyReLU(alpha=0.2,name='conv2_2_relu')(conv2)\n",
        "  #pool2 = slim.max_pool2d(conv2, [2, 2], padding='SAME')\n",
        "  pool2=keras.layers.MaxPooling2D(pool_size=(2,2),padding=\"same\",name='pool2')(conv2)\n",
        "\n",
        "  #conv3 = slim.conv2d(pool2, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv3_1')\n",
        "  conv3=keras.layers.Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',name='conv3_1')(pool2)\n",
        "  conv3=keras.layers.LeakyReLU(alpha=0.2,name='conv3_1_relu')(conv3)\n",
        "  #conv3 = slim.conv2d(conv3, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv3_2')\n",
        "  conv3=keras.layers.Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',name='conv3_2')(conv3)\n",
        "  conv3=keras.layers.LeakyReLU(alpha=0.2,name='conv3_2_relu')(conv3)\n",
        "  #pool3 = slim.max_pool2d(conv3, [2, 2], padding='SAME')\n",
        "  pool3=keras.layers.MaxPooling2D(pool_size=(2,2),padding=\"same\",name='pool3')(conv3)\n",
        "\n",
        "  #conv4 = slim.conv2d(pool3, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv4_1')\n",
        "  conv4=keras.layers.Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',name='conv4_1')(pool3)\n",
        "  conv4=keras.layers.LeakyReLU(alpha=0.2,name='conv4_1_relu')(conv4)\n",
        "  #conv4 = slim.conv2d(conv4, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv4_2')\n",
        "  conv4=keras.layers.Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',name='conv4_2')(conv4)\n",
        "  conv4=keras.layers.LeakyReLU(alpha=0.2,name='conv4_2_relu')(conv4)\n",
        "  #pool4 = slim.max_pool2d(conv4, [2, 2], padding='SAME')\n",
        "  pool4=keras.layers.MaxPooling2D(pool_size=(2,2),padding=\"same\",name='pool4')(conv4)\n",
        "\n",
        "  #conv5 = slim.conv2d(pool4, 512, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv5_1')\n",
        "  conv5=keras.layers.Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',name='conv5_1')(pool4)\n",
        "  conv5=keras.layers.LeakyReLU(alpha=0.2,name='conv5_1_relu')(conv5)\n",
        "  #conv5 = slim.conv2d(conv5, 512, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv5_2')\n",
        "  conv5=keras.layers.Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',name='conv5_2')(conv5)\n",
        "  conv5=keras.layers.LeakyReLU(alpha=0.2,name='conv5_2_relu')(conv5)\n",
        "\n",
        "  #up6 = upsample_and_concat(conv5, conv4, 256, 512)\n",
        "  up6=keras.layers.core.Lambda(upsample_and_concat,arguments={'x2':conv4,'output_channels':256,'in_channels':512,'layer':'upsample_concat_1'},name='upsample_concat_1')(conv5)\n",
        "  #conv6 = slim.conv2d(up6, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv6_1')\n",
        "  conv6=keras.layers.Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',name='conv6_1')(up6)\n",
        "  conv6=keras.layers.LeakyReLU(alpha=0.2,name='conv6_1_relu')(conv6)\n",
        "  #conv6 = slim.conv2d(conv6, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv6_2')\n",
        "  conv6=keras.layers.Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',name='conv6_2')(conv6)\n",
        "  conv6=keras.layers.LeakyReLU(alpha=0.2,name='conv6_2_relu')(conv6)\n",
        "\n",
        "  #up7 = upsample_and_concat(conv6, conv3, 128, 256)\n",
        "  up7=keras.layers.core.Lambda(upsample_and_concat,arguments={'x2':conv3,'output_channels':128,'in_channels':256,'layer':'upsample_concat_2'},name='upsample_concat_2')(conv6)\n",
        "  #conv7 = slim.conv2d(up7, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv7_1')\n",
        "  conv7=keras.layers.Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',name='conv7_1')(up7)\n",
        "  conv7=keras.layers.LeakyReLU(alpha=0.2,name='conv7_1_relu')(conv7)\n",
        "  #conv7 = slim.conv2d(conv7, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv7_2')\n",
        "  conv7=keras.layers.Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',name='conv7_2')(conv7)\n",
        "  conv7=keras.layers.LeakyReLU(alpha=0.2,name='conv7_2_relu')(conv7)\n",
        "\n",
        "  #up8 = upsample_and_concat(conv7, conv2, 64, 128)\n",
        "  up8=keras.layers.core.Lambda(upsample_and_concat,arguments={'x2':conv2,'output_channels':64,'in_channels':128,'layer':'upsample_concat_3'},name='upsample_concat_3')(conv7)\n",
        "  #conv8 = slim.conv2d(up8, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv8_1')\n",
        "  conv8=keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',name='conv8_1')(up8)\n",
        "  conv8=keras.layers.LeakyReLU(alpha=0.2,name='conv8_1_relu')(conv8)\n",
        "  #conv8 = slim.conv2d(conv8, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv8_2')\n",
        "  conv8=keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',name='conv8_2')(conv8)\n",
        "  conv8=keras.layers.LeakyReLU(alpha=0.2,name='conv8_2_relu')(conv8)\n",
        "\n",
        "  #up9 = upsample_and_concat(conv8, conv1, 32, 64)\n",
        "  up9=keras.layers.core.Lambda(upsample_and_concat,arguments={'x2':conv1,'output_channels':32,'in_channels':64,'layer':'upsample_concat_4'},name='upsample_concat_4')(conv8)\n",
        "  #conv9 = slim.conv2d(up9, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv9_1')\n",
        "  conv9=keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same',name='conv9_1')(up9)\n",
        "  conv9=keras.layers.LeakyReLU(alpha=0.2,name='conv9_1_relu')(conv9)\n",
        "  #conv9 = slim.conv2d(conv9, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv9_2')\n",
        "  conv9=keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same',name='conv9_2')(conv9)\n",
        "  conv9=keras.layers.LeakyReLU(alpha=0.2,name='conv9_2_relu')(conv9)\n",
        "  print(\"conv9 shape:\",conv9.shape)\n",
        "\n",
        "  #conv10 = slim.conv2d(conv9, 12, [1, 1], rate=1, activation_fn=None, scope='g_conv10')\n",
        "  conv10=keras.layers.Conv2D(filters=12,kernel_size=(1,1),strides=(1,1),name='conv10')(conv9)\n",
        "  print(\"conv10 shape:\",conv10.shape)\n",
        "  #no activation function for this last layer\n",
        "\n",
        "  predictions = keras.layers.core.Lambda(Depth_to_space_tf,name='depth_to_space')(conv10)\n",
        "  model = keras.models.Model(inputs=inputs, outputs=predictions)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8DyCh5GyNEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pack_raw(raw):\n",
        "    # pack Bayer image to 4 channels\n",
        "    im = raw.raw_image_visible.astype(np.float32)\n",
        "    #print(\"im shape:\",im.shape)\n",
        "    #print(\"im:\")\n",
        "    #print(im)\n",
        "    im = np.maximum(im - 512, 0) / (16383 - 512)  # subtract the black level and normalise with 16383 \n",
        "    ##\n",
        "    # Seems 16383 is the max value due to a 14 bit depth. can be replaced with \n",
        "    ##\n",
        "    #print(\"after normalisation\")\n",
        "    #print(im)\n",
        "\n",
        "    im = np.expand_dims(im, axis=2)\n",
        "    img_shape = im.shape\n",
        "    H = img_shape[0]\n",
        "    W = img_shape[1]\n",
        "    #print(\"after expand dims:%s ,H:%d ,W:%d \" % (img_shape,H,W))\n",
        "\n",
        "    ###\n",
        "    # single bayer pixel format:\n",
        "    # 0:R 1:G\n",
        "    # 2:G 3:B\n",
        "    ###\n",
        "    out = np.concatenate((im[0:H:2, 0:W:2, :], # get the 0th Red as per above format\n",
        "                          im[0:H:2, 1:W:2, :], # get the 1st Green\n",
        "                          im[1:H:2, 1:W:2, :], # get the 2nd Green\n",
        "                          im[1:H:2, 0:W:2, :]), axis=2) # get the 3rd Green\n",
        "    #print(\"out.shape:\",out.shape)\n",
        "    #print(out)\n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6698Y7izIn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sess = tf.Session()\n",
        "# in_image = tf.placeholder(tf.float32, [None, None, None, 4])\n",
        "# gt_image = tf.placeholder(tf.float32, [None, None, None, 3])\n",
        "#out_image = network(in_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXBqHKjN0NB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#G_loss = tf.reduce_mean(tf.abs(out_image - gt_image))\n",
        "# t_vars = tf.trainable_variables()\n",
        "#lr = tf.placeholder(tf.float32)\n",
        "#G_opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(G_loss)\n",
        "#saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75AcCZyH0XXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
        "#if ckpt:\n",
        "#    print('loaded ' + ckpt.model_checkpoint_path)\n",
        "#    saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "###\n",
        "# above commented as not needed can be uncommented\n",
        "###\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjDLxAdO0zds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gt_images = [None] * 6000\n",
        "# input_images = {}\n",
        "# input_images['300'] = [None] * len(train_ids)\n",
        "# input_images['250'] = [None] * len(train_ids)\n",
        "# input_images['100'] = [None] * len(train_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_0TfaMn3xFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#? g_loss = np.zeros((5000, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poYFXTqz5G6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# allfolders = glob.glob('./result/*0')\n",
        "# lastepoch = 0\n",
        "# for folder in allfolders:\n",
        "#     lastepoch = np.maximum(lastepoch, int(folder[-4:]))\n",
        "    \n",
        "###\n",
        "# The above code is used to infer the last completed epoch\n",
        "# ( may be in case a previously saved model is restored)\n",
        "###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaoFTFE05usd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learning_rate = 0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArFQgX5BmH9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_ids[0:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icTY4imvYh2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(train_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkPgT9DWxYhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_id = 1\n",
        "# in_files = glob.glob(input_dir + '%05d_00*.ARW' % train_id) # get all the images path with pattern 0*train_id\n",
        "# #print(in_files)\n",
        "# in_path = in_files[np.random.randint(0, len(in_files))] # get any one image randomly\n",
        "# #print(in_path)\n",
        "# in_fn = os.path.basename(in_path) # get only the full image name\n",
        "# #print(in_fn)\n",
        "\n",
        "# gt_files = glob.glob(gt_dir + '%05d_00*.ARW' % train_id) # get the ground truth image path(s) (only 1 may exist. hence select [0]th below)\n",
        "# #print(gt_files)\n",
        "# gt_path = gt_files[0] # get the first one (as only 1 gt image should exist)\n",
        "# #print(gt_path)\n",
        "# gt_fn = os.path.basename(gt_path) # get only the full image name for gt image\n",
        "# #print(gt_fn)\n",
        "# in_exposure = float(in_fn[9:-5]) # get the exposure for input image\n",
        "# #print(in_exposure)\n",
        "# gt_exposure = float(gt_fn[9:-5]) # get the exposure for gt image\n",
        "# #print(gt_exposure)\n",
        "# ratio = min(gt_exposure / in_exposure, 300)\n",
        "# print(\"ratio:\",ratio)\n",
        "# ########################\n",
        "# gt_raw = rawpy.imread('/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/long/00001_00_10s.ARW')\n",
        "# print(gt_raw.raw_pattern)\n",
        "# print(gt_raw)\n",
        "# im = gt_raw.postprocess(use_camera_wb=True,\n",
        "#                         half_size=False,\n",
        "#                         no_auto_bright=True, output_bps=16)\n",
        "# print(im.shape)\n",
        "# print(im[0:2,:,:])\n",
        "# gt_images = np.expand_dims(np.float32(im / 65535.0),\n",
        "#         axis=0)\n",
        "# print(\"gt_image shape\",gt_images.shape)\n",
        "# print(gt_images[:,0:2,:,:])\n",
        "# ############################\n",
        "# raw = rawpy.imread('/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/short/00001_00_0.04s.ARW')\n",
        "# packed_input_image=pack_raw(raw)\n",
        "# input_img = np.expand_dims(packed_input_image, axis=0) * ratio\n",
        "# print(\"input_image shape\",input_img.shape)\n",
        "# print(input_img[:,0:2,:,:])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZKmZNa_0H7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Params():\n",
        "  def __init__(self,epochs):\n",
        "    shutil.rmtree('/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/result_Sony', ignore_errors=True, onerror=None)\n",
        "    self.input_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/short/'\n",
        "    self.gt_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/long/'\n",
        "    os.mkdir('/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/result_Sony')\n",
        "    self.checkpoint_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/result_Sony/'\n",
        "    self.result_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/result_Sony/'\n",
        "    self.save_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/save_Sony/'\n",
        "    self.epoch_file = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/save_Sony/epochNum.txt'\n",
        "    if os.path.exists(self.save_dir):\n",
        "      pass\n",
        "    else:\n",
        "      os.mkdir('/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/save_Sony')\n",
        "    \n",
        "    \n",
        "    self.epochs=epochs\n",
        "    self.epoch_counter=0\n",
        "    self.ps=512 # batch/patch size for images for training\n",
        "    self.learning_rate=0.0001 # not used in keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoZq9FqA1Elm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Data():\n",
        "  def __init__(self,params):\n",
        "    self.train_fns = glob.glob(params.gt_dir + '0*.ARW')\n",
        "    \"\"\" 0* is for Training images. 1 for Test and 2 for Validation \"\"\"\n",
        "    self.train_ids = [int(os.path.basename(train_fn)[0:5]) for train_fn in self.train_fns]\n",
        "    print(\"Total Train Ids:\",len(self.train_ids))\n",
        "    print(\"Sample Train Ids:\",self.train_ids[0:10])\n",
        "    self.total_train_ids=len(self.train_ids)\n",
        "    \n",
        "    self.valid_fns = glob.glob(params.gt_dir + '2*.ARW')\n",
        "    \"\"\" 0* is for Training images. 1 for Test and 2 for Validation \"\"\"\n",
        "    self.valid_ids = [int(os.path.basename(valid_fn)[0:5]) for valid_fn in self.valid_fns]\n",
        "    print(\"Total Validation Ids:\",len(self.valid_ids))\n",
        "    print(\"Sample Validation Ids:\",self.valid_ids[0:10])\n",
        "    self.total_valid_ids=len(self.valid_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVcN0RNdVzAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader(keras.utils.Sequence):\n",
        "  \"\"\"Class to continously load images\"\"\"\n",
        "  \n",
        "  def __init__(self,params,data):\n",
        "    self.epochs=params.epochs\n",
        "    self.input_dir=params.input_dir\n",
        "    self.gt_dir=params.gt_dir\n",
        "    self.train_ids=data.train_ids\n",
        "    self.gt_image_map=[None] * 6000\n",
        "    self.shuffled_ids=np.random.permutation(len(self.train_ids))\n",
        "#     for index, val in np.ndenumerate(self.shuffled_ids):\n",
        "#       print ('index:{}, image:{}'.format(index[0], val))\n",
        "    self.epoch_counter=0\n",
        "    # self.ind=-1\n",
        "    self.ps=params.ps # batch/patch size for images for training\n",
        "    #self.lock = threading.Lock() # used for making thread safe iterators\n",
        "    #self.on_epoch_end()\n",
        "    \n",
        "#     self.gt_images = [None] * 6000\n",
        "#     self.input_images = {}\n",
        "#     self.input_images['300'] = [None] * len(train_ids)\n",
        "#     self.input_images['250'] = [None] * len(train_ids)\n",
        "#     self.input_images['100'] = [None] * len(train_ids)\n",
        "    \n",
        "  def on_epoch_end(self):\n",
        "    self.shuffled_ids=np.random.permutation(len(self.train_ids))\n",
        "#     print(\"in on epoch end\")\n",
        "\n",
        "  def loadImages(self):\n",
        "    i=0\n",
        "    for train_id in self.train_ids:\n",
        "      if(i>=200):\n",
        "        self.gt_image_map[train_id]=None\n",
        "      else:\n",
        "        print('loading gt_image id:',train_id)\n",
        "        gt_files = glob.glob(self.gt_dir + '%05d_00*.ARW' % train_id) # get the ground truth image path(s) (only 1 may exist. hence select [0]th below)\n",
        "        gt_path = gt_files[0] # get the first one (as only 1 gt image should exist)\n",
        "        gt_raw = rawpy.imread(gt_path)\n",
        "        im = gt_raw.postprocess(use_camera_wb=True,\n",
        "                      half_size=False,\n",
        "                      no_auto_bright=True, output_bps=16)\n",
        "        gt_images = np.expand_dims(np.float32(im / 65535.0),axis=0) # divide by 65535 to normalise (scale between 0 and 1)\n",
        "        self.gt_image_map[train_id]=gt_images\n",
        "        i+=1      \n",
        "    print('gt_images loading done')\n",
        "\n",
        "  def __len__(self):\n",
        "    'Denotes the number of batches per epoch'\n",
        "    return len(self.train_ids)\n",
        "\n",
        "  def __getitem__(self, ind):\n",
        "    'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "    train_id = self.train_ids[self.shuffled_ids[ind]]\n",
        "    #print(\"retireved the train id: {}, ind: {}\".format(train_id,ind))\n",
        "    in_files = glob.glob(self.input_dir + '%05d_00*.ARW' % train_id) # get all the images path with pattern 0*train_id\n",
        "    try:\n",
        "      in_path = in_files[np.random.randint(0, len(in_files))] # get any one image randomly\n",
        "    except:\n",
        "      print(\"exception- retireved the train id:{}, ind:{}, in_files:{}\".format(train_id,ind,in_files))\n",
        "\n",
        "    in_fn = os.path.basename(in_path) # get only the full image name\n",
        "\n",
        "    gt_files = glob.glob(self.gt_dir + '%05d_00*.ARW' % train_id) # get the ground truth image path(s) (only 1 may exist. hence select [0]th below)\n",
        "    gt_path = gt_files[0] # get the first one (as only 1 gt image should exist)\n",
        "    gt_fn = os.path.basename(gt_path) # get only the full image name for gt image\n",
        "    in_exposure = float(in_fn[9:-5]) # get the exposure for input image\n",
        "    gt_exposure = float(gt_fn[9:-5]) # get the exposure for gt image\n",
        "    ratio = min(gt_exposure / in_exposure, 300) # get the amplification ratio\n",
        "\n",
        "    st = time.time()\n",
        "    #cnt += 1\n",
        "\n",
        "    #if input_images[str(ratio)[0:3]][ind] is None: # if image is not loaded (first epoch), load it\n",
        "    raw = rawpy.imread(in_path)\n",
        "    input_images = np.expand_dims(pack_raw(raw), axis=0) * ratio # pack the bayer image in 4 channels of RGBG\n",
        "    if self.gt_image_map[train_id] is None:\n",
        "      print(\"reading gt image\")\n",
        "      # print(\"dict len now:\",len(self.gt_image_map))\n",
        "      gt_raw = rawpy.imread(gt_path)\n",
        "      im = gt_raw.postprocess(use_camera_wb=True,\n",
        "                    half_size=False,\n",
        "                    no_auto_bright=True, output_bps=16)\n",
        "      gt_images = np.expand_dims(np.float32(im / 65535.0),axis=0) # divide by 65535 to normalise (scale between 0 and 1)\n",
        "      self.gt_image_map[train_id]=gt_images\n",
        "    else:\n",
        "      gt_images = self.gt_image_map[train_id]\n",
        "    # crop\n",
        "\n",
        "    H = input_images.shape[1] # get the image height (number of rows)\n",
        "    W = input_images.shape[2] # get the image width (number of columns)\n",
        "\n",
        "    xx = np.random.randint(0, W - self.ps) # get a random number in W-ps (W-512)\n",
        "    yy = np.random.randint(0, H - self.ps) # get a random number in H-ps (H-512)\n",
        "    input_patch = input_images[:, yy:yy + self.ps, xx:xx + self.ps, :]\n",
        "    gt_patch = gt_images[:, yy * 2:yy * 2 + self.ps * 2, xx * 2:xx * 2 + self.ps * 2, :]\n",
        "\n",
        "    if np.random.randint(2) == 1:  # random flip for rows\n",
        "      input_patch = np.flip(input_patch, axis=1)\n",
        "      gt_patch = np.flip(gt_patch, axis=1)\n",
        "    if np.random.randint(2) == 1:  # random flip for columns\n",
        "      input_patch = np.flip(input_patch, axis=2)\n",
        "      gt_patch = np.flip(gt_patch, axis=2)\n",
        "    if np.random.randint(2) == 1:  # random transpose\n",
        "      input_patch = np.transpose(input_patch, (0, 2, 1, 3))\n",
        "      gt_patch = np.transpose(gt_patch, (0, 2, 1, 3))\\\n",
        "\n",
        "    input_patch = np.minimum(input_patch, 1.0)\n",
        "    # print('generated an image with ind:',ind)\n",
        "\n",
        "    return (input_patch,gt_patch)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YECuKfSCS7JW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import datetime\n",
        "# class StoreEpochCallBack(tf.keras.callbacks.Callback):\n",
        "#   def __init__(self, params):\n",
        "#     self.f=open(params.epoch_num_file,\"w\")\n",
        "#   def on_train_batch_begin(self, batch, logs=None):\n",
        "#     print('Training: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))\n",
        "\n",
        "#   def on_train_batch_end(self, batch, logs=None):\n",
        "#     print('Training: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))\n",
        "\n",
        "#   def on_test_batch_begin(self, batch, logs=None):\n",
        "#     print('Evaluating: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))\n",
        "\n",
        "#   def on_test_batch_end(self, batch, logs=None):\n",
        "#     print('Evaluating: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))\n",
        "\n",
        "def train_generator(model,data_gen,epochs,steps_per_epoch,save_fname,epoch_num_file):\n",
        "  print(\"Model Training started!!! Jay Yogeshwar!!!\")\n",
        "  epoch_file=open(epoch_num_file, mode='wt', buffering=1)\n",
        "  epoch_callback = keras.callbacks.LambdaCallback(\n",
        "    on_epoch_end=lambda epoch, logs: epoch_file.write(\n",
        "        json.dumps({'epoch': epoch, 'loss': logs['loss']}) + '\\n'),\n",
        "    on_train_end=lambda logs: epoch_file.close()\n",
        "  )\n",
        "  callbacks = [\n",
        "    epoch_callback,\n",
        "    ModelCheckpoint(period=10,filepath=save_fname, mode='min', monitor='loss', save_weights_only=True, verbose=1, save_best_only=True)\n",
        "  ]\n",
        "  model_history=model.fit_generator(\n",
        "      generator=data_gen,\n",
        "      steps_per_epoch=steps_per_epoch,\n",
        "      epochs=epochs,\n",
        "      callbacks=callbacks,\n",
        "      max_queue_size=5,\n",
        "      workers=2,\n",
        "      use_multiprocessing=True\n",
        "  )\n",
        "  print(\"Model Training completed!!! Jay Yogeshwar!!!\")\n",
        "  return model_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvdY4QQSpiKq",
        "colab_type": "code",
        "outputId": "05ef2d41-f933-450d-ee29-00bbcbb9341c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "  recall = true_positives / (possible_positives + K.epsilon())\n",
        "  return recall\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "  precision = true_positives / (predicted_positives + K.epsilon())\n",
        "  return precision\n",
        "\n",
        "def reduced_mean(y_true,y_pred):\n",
        "  return tf.reduce_mean(tf.abs(y_pred - y_true))\n",
        "\n",
        "epochs=4001\n",
        "params = Params(epochs)\n",
        "data = Data(params)\n",
        "dataloader = DataLoader(params,data)\n",
        "model=build_model()\n",
        "with open('model_summary.txt','w') as fh:\n",
        "    # Pass the file handle in as a lambda function to make it callable\n",
        "    model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
        "keras.utils.vis_utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "model.compile(optimizer='adam',loss=reduced_mean,metrics=['accuracy'])\n",
        "steps_per_epoch=len(data.train_ids)\n",
        "# save_fname = os.path.join(params.save_dir, '%s-e%s.h5' % (dt.datetime.now().strftime('%d%m%Y-%H%M%S'), str(epochs)))\n",
        "save_fname = os.path.join(params.save_dir, '%s-weights-e-{epoch:02d}-l-{loss:.2f}.hdf5' % (dt.datetime.now().strftime('%d%m%Y-%H%M%S')))\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0803 14:02:01.701509 139901636904832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0803 14:02:01.707783 139901636904832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0803 14:02:01.714557 139901636904832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0803 14:02:01.759479 139901636904832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total Train Ids: 161\n",
            "Sample Train Ids: [90, 91, 92, 72, 73, 75, 76, 78, 81, 83]\n",
            "Total Validation Ids: 20\n",
            "Sample Validation Ids: [20079, 20080, 20089, 20107, 20115, 20120, 20147, 20153, 20177, 20005]\n",
            "conv1 shape: (?, ?, ?, 32)\n",
            "conv1 shape: (?, ?, ?, 32)\n",
            "conv1 shape after pool: (?, ?, ?, 32)\n",
            "layer: upsample_concat_1\n",
            "x1 shape: (?, ?, ?, 512)\n",
            "x2 shape: (?, ?, ?, 256)\n",
            "deconvtf shape: (?, ?, ?, 256)\n",
            "deconv_output shape: (?, ?, ?, 512)\n",
            "layer: upsample_concat_1\n",
            "x1 shape: (?, ?, ?, 512)\n",
            "x2 shape: (?, ?, ?, 256)\n",
            "deconvtf shape: (?, ?, ?, 256)\n",
            "deconv_output shape: (?, ?, ?, 512)\n",
            "layer: upsample_concat_2\n",
            "x1 shape: (?, ?, ?, 256)\n",
            "x2 shape: (?, ?, ?, 128)\n",
            "deconvtf shape: (?, ?, ?, 128)\n",
            "deconv_output shape: (?, ?, ?, 256)\n",
            "layer: upsample_concat_2\n",
            "x1 shape: (?, ?, ?, 256)\n",
            "x2 shape: (?, ?, ?, 128)\n",
            "deconvtf shape: (?, ?, ?, 128)\n",
            "deconv_output shape: (?, ?, ?, 256)\n",
            "layer: upsample_concat_3\n",
            "x1 shape: (?, ?, ?, 128)\n",
            "x2 shape: (?, ?, ?, 64)\n",
            "deconvtf shape: (?, ?, ?, 64)\n",
            "deconv_output shape: (?, ?, ?, 128)\n",
            "layer: upsample_concat_3\n",
            "x1 shape: (?, ?, ?, 128)\n",
            "x2 shape: (?, ?, ?, 64)\n",
            "deconvtf shape: (?, ?, ?, 64)\n",
            "deconv_output shape: (?, ?, ?, 128)\n",
            "layer: upsample_concat_4\n",
            "x1 shape: (?, ?, ?, 64)\n",
            "x2 shape: (?, ?, ?, 32)\n",
            "deconvtf shape: (?, ?, ?, 32)\n",
            "deconv_output shape: (?, ?, ?, 64)\n",
            "layer: upsample_concat_4\n",
            "x1 shape: (?, ?, ?, 64)\n",
            "x2 shape: (?, ?, ?, 32)\n",
            "deconvtf shape: (?, ?, ?, 32)\n",
            "deconv_output shape: (?, ?, ?, 64)\n",
            "conv9 shape: (?, ?, ?, 32)\n",
            "conv10 shape: (?, ?, ?, 12)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0803 14:02:02.710633 139901636904832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoSXvhsPndeE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8735e92a-037a-4242-d60b-fdb938ab02bf"
      },
      "source": [
        "dataloader.loadImages()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading gt_image id: 90\n",
            "loading gt_image id: 91\n",
            "loading gt_image id: 92\n",
            "loading gt_image id: 72\n",
            "loading gt_image id: 73\n",
            "loading gt_image id: 75\n",
            "loading gt_image id: 76\n",
            "loading gt_image id: 78\n",
            "loading gt_image id: 81\n",
            "loading gt_image id: 83\n",
            "loading gt_image id: 84\n",
            "loading gt_image id: 85\n",
            "loading gt_image id: 86\n",
            "loading gt_image id: 88\n",
            "loading gt_image id: 94\n",
            "loading gt_image id: 95\n",
            "loading gt_image id: 96\n",
            "loading gt_image id: 97\n",
            "loading gt_image id: 98\n",
            "loading gt_image id: 99\n",
            "loading gt_image id: 100\n",
            "loading gt_image id: 102\n",
            "loading gt_image id: 104\n",
            "loading gt_image id: 108\n",
            "loading gt_image id: 109\n",
            "loading gt_image id: 110\n",
            "loading gt_image id: 112\n",
            "loading gt_image id: 113\n",
            "loading gt_image id: 114\n",
            "loading gt_image id: 117\n",
            "loading gt_image id: 118\n",
            "loading gt_image id: 119\n",
            "loading gt_image id: 121\n",
            "loading gt_image id: 122\n",
            "loading gt_image id: 123\n",
            "loading gt_image id: 124\n",
            "loading gt_image id: 127\n",
            "loading gt_image id: 128\n",
            "loading gt_image id: 129\n",
            "loading gt_image id: 130\n",
            "loading gt_image id: 131\n",
            "loading gt_image id: 132\n",
            "loading gt_image id: 133\n",
            "loading gt_image id: 134\n",
            "loading gt_image id: 135\n",
            "loading gt_image id: 136\n",
            "loading gt_image id: 137\n",
            "loading gt_image id: 138\n",
            "loading gt_image id: 141\n",
            "loading gt_image id: 142\n",
            "loading gt_image id: 143\n",
            "loading gt_image id: 144\n",
            "loading gt_image id: 145\n",
            "loading gt_image id: 146\n",
            "loading gt_image id: 148\n",
            "loading gt_image id: 149\n",
            "loading gt_image id: 150\n",
            "loading gt_image id: 151\n",
            "loading gt_image id: 152\n",
            "loading gt_image id: 154\n",
            "loading gt_image id: 155\n",
            "loading gt_image id: 156\n",
            "loading gt_image id: 157\n",
            "loading gt_image id: 158\n",
            "loading gt_image id: 159\n",
            "loading gt_image id: 160\n",
            "loading gt_image id: 161\n",
            "loading gt_image id: 164\n",
            "loading gt_image id: 165\n",
            "loading gt_image id: 166\n",
            "loading gt_image id: 168\n",
            "loading gt_image id: 169\n",
            "loading gt_image id: 171\n",
            "loading gt_image id: 173\n",
            "loading gt_image id: 174\n",
            "loading gt_image id: 175\n",
            "loading gt_image id: 1\n",
            "loading gt_image id: 2\n",
            "loading gt_image id: 4\n",
            "loading gt_image id: 9\n",
            "loading gt_image id: 10\n",
            "loading gt_image id: 12\n",
            "loading gt_image id: 13\n",
            "loading gt_image id: 14\n",
            "loading gt_image id: 15\n",
            "loading gt_image id: 17\n",
            "loading gt_image id: 18\n",
            "loading gt_image id: 19\n",
            "loading gt_image id: 21\n",
            "loading gt_image id: 23\n",
            "loading gt_image id: 24\n",
            "loading gt_image id: 26\n",
            "loading gt_image id: 27\n",
            "loading gt_image id: 28\n",
            "loading gt_image id: 29\n",
            "loading gt_image id: 31\n",
            "loading gt_image id: 33\n",
            "loading gt_image id: 36\n",
            "loading gt_image id: 37\n",
            "loading gt_image id: 38\n",
            "loading gt_image id: 39\n",
            "loading gt_image id: 41\n",
            "loading gt_image id: 42\n",
            "loading gt_image id: 43\n",
            "loading gt_image id: 44\n",
            "loading gt_image id: 46\n",
            "loading gt_image id: 47\n",
            "loading gt_image id: 48\n",
            "loading gt_image id: 49\n",
            "loading gt_image id: 50\n",
            "loading gt_image id: 51\n",
            "loading gt_image id: 52\n",
            "loading gt_image id: 53\n",
            "loading gt_image id: 56\n",
            "loading gt_image id: 57\n",
            "loading gt_image id: 58\n",
            "loading gt_image id: 59\n",
            "loading gt_image id: 60\n",
            "loading gt_image id: 62\n",
            "loading gt_image id: 63\n",
            "loading gt_image id: 64\n",
            "loading gt_image id: 65\n",
            "loading gt_image id: 66\n",
            "loading gt_image id: 67\n",
            "loading gt_image id: 70\n",
            "loading gt_image id: 71\n",
            "loading gt_image id: 179\n",
            "loading gt_image id: 180\n",
            "loading gt_image id: 181\n",
            "loading gt_image id: 182\n",
            "loading gt_image id: 183\n",
            "loading gt_image id: 184\n",
            "loading gt_image id: 186\n",
            "loading gt_image id: 189\n",
            "loading gt_image id: 190\n",
            "loading gt_image id: 194\n",
            "loading gt_image id: 195\n",
            "loading gt_image id: 196\n",
            "loading gt_image id: 197\n",
            "loading gt_image id: 200\n",
            "loading gt_image id: 202\n",
            "loading gt_image id: 204\n",
            "loading gt_image id: 205\n",
            "loading gt_image id: 206\n",
            "loading gt_image id: 207\n",
            "loading gt_image id: 209\n",
            "loading gt_image id: 212\n",
            "loading gt_image id: 214\n",
            "loading gt_image id: 215\n",
            "loading gt_image id: 216\n",
            "loading gt_image id: 218\n",
            "loading gt_image id: 219\n",
            "loading gt_image id: 220\n",
            "loading gt_image id: 221\n",
            "loading gt_image id: 222\n",
            "loading gt_image id: 223\n",
            "loading gt_image id: 224\n",
            "loading gt_image id: 225\n",
            "loading gt_image id: 230\n",
            "loading gt_image id: 231\n",
            "loading gt_image id: 232\n",
            "gt_images loading done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ8IR20yraX8",
        "colab_type": "code",
        "outputId": "c18b2a47-5272-4665-cf93-0259cbead126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "\"\"\" ================ TRAIN THE MODEL ================ \"\"\"\n",
        "# steps_per_epoch=10\n",
        "model_history=train_generator(model,dataloader,params.epochs,steps_per_epoch,save_fname,params.epoch_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Training started!!! Jay Yogeshwar!!!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0803 14:08:38.239572 139901636904832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "W0803 14:08:38.788922 139901636904832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4001\n",
            "161/161 [==============================] - 119s 742ms/step - loss: 0.1508 - acc: 0.6036\n",
            "Epoch 2/4001\n",
            "161/161 [==============================] - 64s 395ms/step - loss: 0.1395 - acc: 0.6102\n",
            "Epoch 3/4001\n",
            "161/161 [==============================] - 53s 329ms/step - loss: 0.0719 - acc: 0.7039\n",
            "Epoch 4/4001\n",
            "161/161 [==============================] - 52s 324ms/step - loss: 0.0660 - acc: 0.7168\n",
            "Epoch 5/4001\n",
            "  5/161 [..............................] - ETA: 1:00 - loss: 0.0561 - acc: 0.7753"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6rt0FGT6jY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for epoch in range(lastepoch, 4001):\n",
        "#     #if os.path.isdir('result/%04d' % epoch):\n",
        "#     #    continue\n",
        "#     ###\n",
        "#     # used for skipping the current epoch if the checkpoint directory exists\n",
        "#     ###\n",
        "#     cnt = 0\n",
        "#     if epoch > 2000:\n",
        "#         learning_rate = 1e-5\n",
        "\n",
        "#     for ind in np.random.permutation(len(train_ids)):\n",
        "\n",
        "#         # get the path from image id\n",
        "\n",
        "#         train_id = train_ids[ind]\n",
        "#         in_files = glob.glob(input_dir + '%05d_00*.ARW' % train_id) # get all the images path with pattern 0*train_id\n",
        "#         in_path = in_files[np.random.randint(0, len(in_files))] # get any one image randomly\n",
        "#         in_fn = os.path.basename(in_path) # get only the full image name\n",
        "\n",
        "#         gt_files = glob.glob(gt_dir + '%05d_00*.ARW' % train_id) # get the ground truth image path(s) (only 1 may exist. hence select [0]th below)\n",
        "#         gt_path = gt_files[0] # get the first one (as only 1 gt image should exist)\n",
        "#         gt_fn = os.path.basename(gt_path) # get only the full image name for gt image\n",
        "#         in_exposure = float(in_fn[9:-5]) # get the exposure for input image\n",
        "#         gt_exposure = float(gt_fn[9:-5]) # get the exposure for gt image\n",
        "#         ratio = min(gt_exposure / in_exposure, 300) # get the amplification ratio\n",
        "\n",
        "#         st = time.time()\n",
        "#         cnt += 1\n",
        "\n",
        "#         if input_images[str(ratio)[0:3]][ind] is None: # if image is not loaded (first epoch), load it\n",
        "#             raw = rawpy.imread(in_path)\n",
        "#             input_images[str(ratio)[0:3]][ind] = \\\n",
        "#                 np.expand_dims(pack_raw(raw), axis=0) * ratio # pack the bayer image in 4 channels of RGBG\n",
        "\n",
        "#             gt_raw = rawpy.imread(gt_path)\n",
        "#             im = gt_raw.postprocess(use_camera_wb=True,\n",
        "#                                     half_size=False,\n",
        "#                                     no_auto_bright=True, output_bps=16)\n",
        "#             gt_images[ind] = np.expand_dims(np.float32(im / 65535.0),axis=0) # divide by 65535 to normalise (scale between 0 and 1)\n",
        "\n",
        "#         # crop\n",
        "\n",
        "#         H = input_images[str(ratio)[0:3]][ind].shape[1] # get the image height (number of rows)\n",
        "#         W = input_images[str(ratio)[0:3]][ind].shape[2] # get the image width (number of columns)\n",
        "\n",
        "#         xx = np.random.randint(0, W - ps) # get a random number in W-ps (W-512)\n",
        "#         yy = np.random.randint(0, H - ps) # get a random number in H-ps (H-512)\n",
        "#         input_patch = input_images[str(ratio)[0:3]][ind][:, yy:yy + ps,\n",
        "#                 xx:xx + ps, :]\n",
        "#         gt_patch = gt_images[ind][:, yy * 2:yy * 2 + ps * 2, xx * 2:xx\n",
        "#                                   * 2 + ps * 2, :]\n",
        "\n",
        "#         if np.random.randint(2) == 1:  # random flip for rows\n",
        "#             input_patch = np.flip(input_patch, axis=1)\n",
        "#             gt_patch = np.flip(gt_patch, axis=1)\n",
        "#         if np.random.randint(2) == 1:  # random flip for columns\n",
        "#             input_patch = np.flip(input_patch, axis=2)\n",
        "#             gt_patch = np.flip(gt_patch, axis=2)\n",
        "#         if np.random.randint(2) == 1:  # random transpose\n",
        "#             input_patch = np.transpose(input_patch, (0, 2, 1, 3))\n",
        "#             gt_patch = np.transpose(gt_patch, (0, 2, 1, 3))\\\n",
        "\n",
        "#         input_patch = np.minimum(input_patch, 1.0)\n",
        "\n",
        "#         (_, G_current, output) = sess.run([G_opt, G_loss, out_image],\n",
        "#                 feed_dict={in_image: input_patch, gt_image: gt_patch,\n",
        "#                 lr: learning_rate})\n",
        "#         output = np.minimum(np.maximum(output, 0), 1)\n",
        "#         g_loss[ind] = G_current\n",
        "\n",
        "#         print '%d %d Loss=%.3f Time=%.3f' % (epoch, cnt,\n",
        "#                 np.mean(g_loss[np.where(g_loss)]), time.time() - st)\n",
        "\n",
        "#         if epoch % save_freq == 0:\n",
        "#             if not os.path.isdir(result_dir + '%04d' % epoch):\n",
        "#                 os.makedirs(result_dir + '%04d' % epoch)\n",
        "\n",
        "#             temp = np.concatenate((gt_patch[0, :, :, :], output[0, :, :\n",
        "#                                   , :]), axis=1)\n",
        "#             scipy.misc.toimage(temp * 255, high=255, low=0, cmin=0,\n",
        "#                                cmax=255).save(result_dir\n",
        "#                     + '%04d/%05d_00_train_%d.jpg' % (epoch, train_id,\n",
        "#                     ratio))\n",
        "\n",
        "#     saver.save(sess, checkpoint_dir + 'model.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir4Xcjn_mfhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import multiprocessing\n",
        "\n",
        "multiprocessing.gpu_count()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}