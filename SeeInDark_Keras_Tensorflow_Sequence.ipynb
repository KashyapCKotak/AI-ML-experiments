{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SeeInDark_Keras_Tensorflow_Sequence.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KashyapCKotak/AI-ML-experiments/blob/master/SeeInDark_Keras_Tensorflow_Sequence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuMNVBqt0u-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import requests\n",
        "# import os\n",
        "\n",
        "# def download_file_from_google_drive(id, destination):\n",
        "#     URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "#     session = requests.Session()\n",
        "\n",
        "#     response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "#     token = get_confirm_token(response)\n",
        "\n",
        "#     if token:\n",
        "#         params = { 'id' : id, 'confirm' : token }\n",
        "#         response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "#     save_response_content(response, destination)    \n",
        "\n",
        "# def get_confirm_token(response):\n",
        "#     for key, value in response.cookies.items():\n",
        "#         if key.startswith('download_warning'):\n",
        "#             return value\n",
        "\n",
        "#     return None\n",
        "\n",
        "# def save_response_content(response, destination):\n",
        "#     CHUNK_SIZE = 32768\n",
        "\n",
        "#     with open(destination, \"wb\") as f:\n",
        "#         for chunk in response.iter_content(CHUNK_SIZE):\n",
        "#             if chunk: # filter out keep-alive new chunks\n",
        "#                 f.write(chunk)\n",
        "\n",
        "\n",
        "\n",
        "# print('Dowloading Sony subset... (25GB)')\n",
        "# download_file_from_google_drive('10kpAcvldtcb9G2ze5hTcF1odzu4V_Zvh', './Sony.zip')\n",
        "\n",
        "# #print('Dowloading Fuji subset... (52GB)')\n",
        "# #download_file_from_google_drive('12hvKCjwuilKTZPe9EZ7ZTb-azOmUA3HT', 'dataset/Fuji.zip')\n",
        "\n",
        "# os.system('unzip ./Sony.zip -d dataset')\n",
        "# #os.system('unzip dataset/Fuji.zip -d dataset')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsP1lrRN-HPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import shutil\n",
        "# shutil.rmtree('result_Sony', ignore_errors=True, onerror=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-_85I6g3eA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# os.system('unzip ./Sony.zip -d dataset')\n",
        "#os.system('unzip dataset/Fuji.zip -d dataset')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDQVxKF8nooG",
        "colab_type": "code",
        "outputId": "28c7d1e3-c998-4657-b377-54a014a9f633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yyhvphaOsft",
        "colab_type": "code",
        "outputId": "0933235a-dc0a-4a05-cbd4-9cbc9d05b497",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import json\n",
        "import glob\n",
        "import os\n",
        "epoch_file='/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/save_Sony/epochNum.txt'\n",
        "save_dir='/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/save_Sony/'\n",
        "last_epoch=0\n",
        "last_line=\"\"\n",
        "with open(epoch_file, mode='r', buffering=1) as epoch_file:\n",
        "  last_line=list(epoch_file)[-1]\n",
        "last_epoch=json.loads(last_line)['epoch']\n",
        "print(\"Epoch to start:\",last_epoch)\n",
        "list_of_files=glob.glob(save_dir+\"*.hdf5\")\n",
        "if not last_epoch<10:\n",
        "  latest_file_path = max(list_of_files, key=os.path.getctime)\n",
        "  print (\"Latest file path:\",latest_file_path)\n",
        "print(int(latest_file_path.split('/')[-1].split('-')[-3])-1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch to start: 15\n",
            "Latest file path: /content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/save_Sony/07082019-105227-weights-e-15-l-0.05.hdf5\n",
            "14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJhrjFQXhTZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open('/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/save_Sony/epochNum.txt', mode='w', buffering=1) as epoch_file:\n",
        "#   epoch_file.write(json.dumps({'epoch': -1, 'loss': 0, 'datetime': 'dummy start line'}) + '\\n'),"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9yF04nOlUCP",
        "colab_type": "text"
      },
      "source": [
        "**Main Train Code:**\n",
        "================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_zLVCtYlfSH",
        "colab_type": "code",
        "outputId": "7571cdc0-bfe6-47d0-e577-70ea123995e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "!pip install rawpy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rawpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/04/997062d83766f5fbfa4dc0d20180c5085b55a74e69559e9cb6d4f1e9550e/rawpy-0.13.1-cp36-cp36m-manylinux1_x86_64.whl (682kB)\n",
            "\r\u001b[K     |▌                               | 10kB 18.6MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 5.2MB/s eta 0:00:01\r\u001b[K     |█▍                              | 30kB 7.4MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 5.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 6.4MB/s eta 0:00:01\r\u001b[K     |██▉                             | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 7.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 7.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 92kB 8.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 122kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 143kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 153kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 174kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 184kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 204kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 215kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 235kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 245kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 266kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 286kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 307kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 317kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 327kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 337kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 348kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 358kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 368kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 378kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 389kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 399kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 409kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 419kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 430kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 440kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 450kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 460kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 471kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 481kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 491kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 501kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 512kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 522kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 532kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 542kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 552kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 563kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 573kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 583kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 593kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 604kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 614kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 624kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 634kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 645kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 655kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 665kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 675kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 686kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rawpy) (1.16.4)\n",
            "Installing collected packages: rawpy\n",
            "Successfully installed rawpy-0.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IogQOu0slZNT",
        "colab_type": "code",
        "outputId": "71f9de83-80ad-4bce-df65-fda453c33e0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import division\n",
        "import os, time, scipy.io\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import rawpy\n",
        "import glob\n",
        "import keras\n",
        "import shutil\n",
        "import datetime as dt\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
        "import threading\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv0LQyX43bPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install -q tf-nightly-2.0-preview\n",
        "# # Load the TensorBoard notebook extension\n",
        "# %load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gTj24DXlazJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import shutil\n",
        "# shutil.rmtree('result_Sony', ignore_errors=True, onerror=None)\n",
        "\n",
        "# input_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/short/'\n",
        "# gt_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/long/'\n",
        "# os.mkdir('result_Sony')\n",
        "# checkpoint_dir = './result_Sony/'\n",
        "# result_dir = './result_Sony/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vexCrDNtiIrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lrelu(x): # not used. Used Kears LeakyReLU with alpha 0.2 instead\n",
        "    return tf.maximum(x * 0.2, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZkJ3o0ZiKQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" This cell contains the custom Lambda layers to be used in building the  keras mdoel \"\"\"\n",
        "def upsample_and_concat(x1,x2,output_channels,in_channels,layer,verbose=False):\n",
        "  if(verbose):\n",
        "    print(\"layer:\",layer)\n",
        "  pool_size = 2\n",
        "  deconv_filter = tf.Variable(tf.truncated_normal([pool_size, pool_size, output_channels, in_channels], stddev=0.02))\n",
        "  if(verbose):\n",
        "    print(\"x1 shape:\",x1.shape)\n",
        "    print(\"x2 shape:\",x2.shape)\n",
        "  deconvtf=tf.nn.conv2d_transpose(x1, deconv_filter, tf.shape(x2), strides=[1, pool_size, pool_size, 1])\n",
        "  if(verbose):\n",
        "    print(\"deconvtf shape:\",deconvtf.shape)\n",
        "  #deconv=keras.layers.Conv2DTranspose(filters=output_channels,kernel_size=(pool_size, pool_size),strides=(pool_size, pool_size))(x1)\n",
        "  #print(\"deconvk shape:\",deconv.shape)\n",
        "\n",
        "  deconv_output = tf.concat([deconvtf, x2], 3)\n",
        "  if(verbose):\n",
        "    print(\"deconv_output shape:\",deconv_output.shape)\n",
        "  deconv_output.set_shape([None, None, None, output_channels * 2])\n",
        "\n",
        "  return deconv_output\n",
        "\n",
        "def Depth_to_space_tf(input):\n",
        "  return tf.depth_to_space(input, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cRpNNVlYXKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testing code\n",
        "# t=tf.ones([1,450,350,4])\n",
        "# deconv_filter = tf.Variable(tf.truncated_normal([2, 2, 256, 512], stddev=0.02))\n",
        "# tf.nn.conv2d_transpose(t, deconv_filter, [1,450,350,], strides=[1, pool_size, pool_size, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUz7pW3dm8Qh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  inputs=keras.layers.Input(shape=(None, None, 4))\n",
        "  #definition: slim.conv2d(inputs,number of outputs, kernel shape)\n",
        "  #definition: slim.max_pool2d(inputsconv2d_transpose ,kernel_size, padding)\n",
        "  #conv1 = slim.conv2d(input, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_1')\n",
        "  conv1=keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same',name='conv1_1')(inputs)\n",
        "  conv1=keras.layers.LeakyReLU(alpha=0.2,name='conv1_1_relu')(conv1)\n",
        "  print(\"conv1 shape:\",conv1.shape)\n",
        "  #conv1 = slim.conv2d(conv1, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_2')\n",
        "  conv1=keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same',name='conv1_2')(conv1)\n",
        "  conv1=keras.layers.LeakyReLU(alpha=0.2,name='conv1_2_relu')(conv1)\n",
        "  print(\"conv1 shape:\",conv1.shape)\n",
        "  #pool1 = slim.max_pool2d(conv1, [2, 2], padding='SAME')\n",
        "  pool1=keras.layers.MaxPooling2D(pool_size=(2,2),padding=\"same\",name='pool1')(conv1)\n",
        "  print(\"conv1 shape after pool:\",pool1.shape)\n",
        "\n",
        "  #conv2 = slim.conv2d(pool1, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv2_1')\n",
        "  conv2=keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',name='conv2_1')(pool1)\n",
        "  conv2=keras.layers.LeakyReLU(alpha=0.2,name='conv2_1_relu')(conv2)\n",
        "  #conv2 = slim.conv2d(conv2, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv2_2')\n",
        "  conv2=keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',name='conv2_2')(conv2)\n",
        "  conv2=keras.layers.LeakyReLU(alpha=0.2,name='conv2_2_relu')(conv2)\n",
        "  #pool2 = slim.max_pool2d(conv2, [2, 2], padding='SAME')\n",
        "  pool2=keras.layers.MaxPooling2D(pool_size=(2,2),padding=\"same\",name='pool2')(conv2)\n",
        "\n",
        "  #conv3 = slim.conv2d(pool2, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv3_1')\n",
        "  conv3=keras.layers.Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',name='conv3_1')(pool2)\n",
        "  conv3=keras.layers.LeakyReLU(alpha=0.2,name='conv3_1_relu')(conv3)\n",
        "  #conv3 = slim.conv2d(conv3, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv3_2')\n",
        "  conv3=keras.layers.Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',name='conv3_2')(conv3)\n",
        "  conv3=keras.layers.LeakyReLU(alpha=0.2,name='conv3_2_relu')(conv3)\n",
        "  #pool3 = slim.max_pool2d(conv3, [2, 2], padding='SAME')\n",
        "  pool3=keras.layers.MaxPooling2D(pool_size=(2,2),padding=\"same\",name='pool3')(conv3)\n",
        "\n",
        "  #conv4 = slim.conv2d(pool3, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv4_1')\n",
        "  conv4=keras.layers.Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',name='conv4_1')(pool3)\n",
        "  conv4=keras.layers.LeakyReLU(alpha=0.2,name='conv4_1_relu')(conv4)\n",
        "  #conv4 = slim.conv2d(conv4, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv4_2')\n",
        "  conv4=keras.layers.Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',name='conv4_2')(conv4)\n",
        "  conv4=keras.layers.LeakyReLU(alpha=0.2,name='conv4_2_relu')(conv4)\n",
        "  #pool4 = slim.max_pool2d(conv4, [2, 2], padding='SAME')\n",
        "  pool4=keras.layers.MaxPooling2D(pool_size=(2,2),padding=\"same\",name='pool4')(conv4)\n",
        "\n",
        "  #conv5 = slim.conv2d(pool4, 512, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv5_1')\n",
        "  conv5=keras.layers.Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',name='conv5_1')(pool4)\n",
        "  conv5=keras.layers.LeakyReLU(alpha=0.2,name='conv5_1_relu')(conv5)\n",
        "  #conv5 = slim.conv2d(conv5, 512, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv5_2')\n",
        "  conv5=keras.layers.Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',name='conv5_2')(conv5)\n",
        "  conv5=keras.layers.LeakyReLU(alpha=0.2,name='conv5_2_relu')(conv5)\n",
        "\n",
        "  #up6 = upsample_and_concat(conv5, conv4, 256, 512)\n",
        "  up6=keras.layers.core.Lambda(upsample_and_concat,arguments={'x2':conv4,'output_channels':256,'in_channels':512,'layer':'upsample_concat_1','verbose':False},name='upsample_concat_1')(conv5)\n",
        "  #conv6 = slim.conv2d(up6, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv6_1')\n",
        "  conv6=keras.layers.Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',name='conv6_1')(up6)\n",
        "  conv6=keras.layers.LeakyReLU(alpha=0.2,name='conv6_1_relu')(conv6)\n",
        "  #conv6 = slim.conv2d(conv6, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv6_2')\n",
        "  conv6=keras.layers.Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',name='conv6_2')(conv6)\n",
        "  conv6=keras.layers.LeakyReLU(alpha=0.2,name='conv6_2_relu')(conv6)\n",
        "\n",
        "  #up7 = upsample_and_concat(conv6, conv3, 128, 256)\n",
        "  up7=keras.layers.core.Lambda(upsample_and_concat,arguments={'x2':conv3,'output_channels':128,'in_channels':256,'layer':'upsample_concat_2','verbose':False},name='upsample_concat_2')(conv6)\n",
        "  #conv7 = slim.conv2d(up7, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv7_1')\n",
        "  conv7=keras.layers.Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',name='conv7_1')(up7)\n",
        "  conv7=keras.layers.LeakyReLU(alpha=0.2,name='conv7_1_relu')(conv7)\n",
        "  #conv7 = slim.conv2d(conv7, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv7_2')\n",
        "  conv7=keras.layers.Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',name='conv7_2')(conv7)\n",
        "  conv7=keras.layers.LeakyReLU(alpha=0.2,name='conv7_2_relu')(conv7)\n",
        "\n",
        "  #up8 = upsample_and_concat(conv7, conv2, 64, 128)\n",
        "  up8=keras.layers.core.Lambda(upsample_and_concat,arguments={'x2':conv2,'output_channels':64,'in_channels':128,'layer':'upsample_concat_3','verbose':False},name='upsample_concat_3')(conv7)\n",
        "  #conv8 = slim.conv2d(up8, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv8_1')\n",
        "  conv8=keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',name='conv8_1')(up8)\n",
        "  conv8=keras.layers.LeakyReLU(alpha=0.2,name='conv8_1_relu')(conv8)\n",
        "  #conv8 = slim.conv2d(conv8, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv8_2')\n",
        "  conv8=keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',name='conv8_2')(conv8)\n",
        "  conv8=keras.layers.LeakyReLU(alpha=0.2,name='conv8_2_relu')(conv8)\n",
        "\n",
        "  #up9 = upsample_and_concat(conv8, conv1, 32, 64)\n",
        "  up9=keras.layers.core.Lambda(upsample_and_concat,arguments={'x2':conv1,'output_channels':32,'in_channels':64,'layer':'upsample_concat_4','verbose':False},name='upsample_concat_4')(conv8)\n",
        "  #conv9 = slim.conv2d(up9, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv9_1')\n",
        "  conv9=keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same',name='conv9_1')(up9)\n",
        "  conv9=keras.layers.LeakyReLU(alpha=0.2,name='conv9_1_relu')(conv9)\n",
        "  #conv9 = slim.conv2d(conv9, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv9_2')\n",
        "  conv9=keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same',name='conv9_2')(conv9)\n",
        "  conv9=keras.layers.LeakyReLU(alpha=0.2,name='conv9_2_relu')(conv9)\n",
        "  print(\"conv9 shape:\",conv9.shape)\n",
        "\n",
        "  #conv10 = slim.conv2d(conv9, 12, [1, 1], rate=1, activation_fn=None, scope='g_conv10')\n",
        "  conv10=keras.layers.Conv2D(filters=12,kernel_size=(1,1),strides=(1,1),name='conv10')(conv9)\n",
        "  print(\"conv10 shape:\",conv10.shape)\n",
        "  #no activation function for this last layer\n",
        "\n",
        "  predictions = keras.layers.core.Lambda(Depth_to_space_tf,name='depth_to_space')(conv10)\n",
        "  model = keras.models.Model(inputs=inputs, outputs=predictions)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8DyCh5GyNEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pack_raw(raw):\n",
        "    # pack Bayer image to 4 channels\n",
        "    im = raw.raw_image_visible.astype(np.float32)\n",
        "    #print(\"im shape:\",im.shape)\n",
        "    #print(\"im:\")\n",
        "    #print(im)\n",
        "    im = np.maximum(im - 512, 0) / (16383 - 512)  # subtract the black level and normalise with 16383 \n",
        "    ##\n",
        "    # Seems 16383 is the max value due to a 14 bit depth. can be replaced with \n",
        "    ##\n",
        "    #print(\"after normalisation\")\n",
        "    #print(im)\n",
        "\n",
        "    im = np.expand_dims(im, axis=2)\n",
        "    img_shape = im.shape\n",
        "    H = img_shape[0]\n",
        "    W = img_shape[1]\n",
        "    #print(\"after expand dims:%s ,H:%d ,W:%d \" % (img_shape,H,W))\n",
        "\n",
        "    ###\n",
        "    # single bayer pixel format:\n",
        "    # 0:R 1:G\n",
        "    # 2:G 3:B\n",
        "    ###\n",
        "    out = np.concatenate((im[0:H:2, 0:W:2, :], # get the 0th Red as per above format\n",
        "                          im[0:H:2, 1:W:2, :], # get the 1st Green\n",
        "                          im[1:H:2, 1:W:2, :], # get the 2nd Green\n",
        "                          im[1:H:2, 0:W:2, :]), axis=2) # get the 3rd Green\n",
        "    #print(\"out.shape:\",out.shape)\n",
        "    #print(out)\n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZKmZNa_0H7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Params():\n",
        "  def __init__(self):\n",
        "    shutil.rmtree('/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/result_Sony', ignore_errors=True, onerror=None)\n",
        "    self.input_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/short/'\n",
        "    self.gt_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/long/'\n",
        "    os.mkdir('/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/result_Sony')\n",
        "    self.checkpoint_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/result_Sony/'\n",
        "    self.result_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/result_Sony/'\n",
        "    self.save_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/save_Sony/'\n",
        "    self.epoch_file = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/save_Sony/epochNum.txt'\n",
        "    self.tensorboard_log_dir = '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/tensorboard'\n",
        "    if os.path.exists(self.tensorboard_log_dir):\n",
        "      pass\n",
        "    else:\n",
        "      os.mkdir(self.tensorboard_log_dir)\n",
        "    if os.path.exists(self.save_dir):\n",
        "      pass\n",
        "    else:\n",
        "      os.mkdir('/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/save_Sony')\n",
        "    \n",
        "    \n",
        "    self.epochs=4000\n",
        "    self.epoch_counter=0\n",
        "    self.ps=512 # batch/patch size for images for training\n",
        "    self.learning_rate=0.0001 # not used in keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoZq9FqA1Elm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Data():\n",
        "  def __init__(self,params):\n",
        "    self.train_fns = glob.glob(params.gt_dir + '0*.ARW')\n",
        "    \"\"\" 0* is for Training images. 1 for Test and 2 for Validation \"\"\"\n",
        "    self.train_ids = [int(os.path.basename(train_fn)[0:5]) for train_fn in self.train_fns]\n",
        "    print(\"Total Train Ids:\",len(self.train_ids))\n",
        "    print(\"Sample Train Ids:\",self.train_ids[0:10])\n",
        "    self.total_train_ids=len(self.train_ids)\n",
        "    \n",
        "    self.valid_fns = glob.glob(params.gt_dir + '2*.ARW')\n",
        "    \"\"\" 0* is for Training images. 1 for Test and 2 for Validation \"\"\"\n",
        "    self.valid_ids = [int(os.path.basename(valid_fn)[0:5]) for valid_fn in self.valid_fns]\n",
        "    print(\"Total Validation Ids:\",len(self.valid_ids))\n",
        "    print(\"Sample Validation Ids:\",self.valid_ids[0:10])\n",
        "    self.total_valid_ids=len(self.valid_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVcN0RNdVzAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader(keras.utils.Sequence):\n",
        "  \"\"\"Class to continously load images\"\"\"\n",
        "  \n",
        "  def __init__(self,params,data):\n",
        "    self.epochs=params.epochs\n",
        "    self.input_dir=params.input_dir\n",
        "    self.gt_dir=params.gt_dir\n",
        "    self.train_ids=data.train_ids\n",
        "    self.gt_image_map=[None] * 6000\n",
        "    self.shuffled_ids=np.random.permutation(len(self.train_ids))\n",
        "#     for index, val in np.ndenumerate(self.shuffled_ids):\n",
        "#       print ('index:{}, image:{}'.format(index[0], val))\n",
        "    self.epoch_counter=0\n",
        "    # self.ind=-1\n",
        "    self.ps=params.ps # batch/patch size for images for training\n",
        "    #self.lock = threading.Lock() # used for making thread safe iterators\n",
        "    #self.on_epoch_end()\n",
        "    \n",
        "#     self.gt_images = [None] * 6000\n",
        "#     self.input_images = {}\n",
        "#     self.input_images['300'] = [None] * len(train_ids)\n",
        "#     self.input_images['250'] = [None] * len(train_ids)\n",
        "#     self.input_images['100'] = [None] * len(train_ids)\n",
        "    \n",
        "  def on_epoch_end(self):\n",
        "    self.shuffled_ids=np.random.permutation(len(self.train_ids))\n",
        "#     print(\"in on epoch end\")\n",
        "\n",
        "  def loadImages(self):\n",
        "    i=0\n",
        "    for train_id in self.train_ids:\n",
        "      if(i>=200):\n",
        "        self.gt_image_map[train_id]=None\n",
        "      else:\n",
        "        print('loading gt_image id:',train_id)\n",
        "        gt_files = glob.glob(self.gt_dir + '%05d_00*.ARW' % train_id) # get the ground truth image path(s) (only 1 may exist. hence select [0]th below)\n",
        "        gt_path = gt_files[0] # get the first one (as only 1 gt image should exist)\n",
        "        gt_raw = rawpy.imread(gt_path)\n",
        "        im = gt_raw.postprocess(use_camera_wb=True,\n",
        "                      half_size=False,\n",
        "                      no_auto_bright=True, output_bps=16)\n",
        "        gt_images = np.expand_dims(np.float32(im / 65535.0),axis=0) # divide by 65535 to normalise (scale between 0 and 1)\n",
        "        self.gt_image_map[train_id]=gt_images\n",
        "        i+=1      \n",
        "    print('gt_images loading done')\n",
        "\n",
        "  def __len__(self):\n",
        "    'Denotes the number of batches per epoch'\n",
        "    return len(self.train_ids)\n",
        "\n",
        "  def __getitem__(self, ind):\n",
        "    'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "    train_id = self.train_ids[self.shuffled_ids[ind]]\n",
        "    #print(\"retireved the train id: {}, ind: {}\".format(train_id,ind))\n",
        "    in_files = glob.glob(self.input_dir + '%05d_00*.ARW' % train_id) # get all the images path with pattern 0*train_id\n",
        "    try:\n",
        "      in_path = in_files[np.random.randint(0, len(in_files))] # get any one image randomly\n",
        "    except:\n",
        "      print(\"exception- retireved the train id:{}, ind:{}, in_files:{}\".format(train_id,ind,in_files))\n",
        "\n",
        "    in_fn = os.path.basename(in_path) # get only the full image name\n",
        "\n",
        "    gt_files = glob.glob(self.gt_dir + '%05d_00*.ARW' % train_id) # get the ground truth image path(s) (only 1 may exist. hence select [0]th below)\n",
        "    gt_path = gt_files[0] # get the first one (as only 1 gt image should exist)\n",
        "    gt_fn = os.path.basename(gt_path) # get only the full image name for gt image\n",
        "    in_exposure = float(in_fn[9:-5]) # get the exposure for input image\n",
        "    gt_exposure = float(gt_fn[9:-5]) # get the exposure for gt image\n",
        "    ratio = min(gt_exposure / in_exposure, 300) # get the amplification ratio\n",
        "\n",
        "    start = time.process_time()\n",
        "    #cnt += 1\n",
        "\n",
        "    #if input_images[str(ratio)[0:3]][ind] is None: # if image is not loaded (first epoch), load it\n",
        "    raw = rawpy.imread(in_path)\n",
        "    input_images = np.expand_dims(pack_raw(raw), axis=0) * ratio # pack the bayer image in 4 channels of RGBG\n",
        "    if self.gt_image_map[train_id] is None:\n",
        "      print(\"reading gt image\")\n",
        "      # print(\"dict len now:\",len(self.gt_image_map))\n",
        "      gt_raw = rawpy.imread(gt_path)\n",
        "      im = gt_raw.postprocess(use_camera_wb=True,\n",
        "                    half_size=False,\n",
        "                    no_auto_bright=True, output_bps=16)\n",
        "      gt_images = np.expand_dims(np.float32(im / 65535.0),axis=0) # divide by 65535 to normalise (scale between 0 and 1)\n",
        "      self.gt_image_map[train_id]=gt_images\n",
        "    else:\n",
        "      gt_images = self.gt_image_map[train_id]\n",
        "    # crop\n",
        "#     print(\"time taken for reading image %d:%s with in_path: %s & gt_path:%s\" % (train_id,(time.process_time() - start),in_path,gt_path))\n",
        "\n",
        "    H = input_images.shape[1] # get the image height (number of rows)\n",
        "    W = input_images.shape[2] # get the image width (number of columns)\n",
        "\n",
        "    xx = np.random.randint(0, W - self.ps) # get a random number in W-ps (W-512)\n",
        "    yy = np.random.randint(0, H - self.ps) # get a random number in H-ps (H-512)\n",
        "    input_patch = input_images[:, yy:yy + self.ps, xx:xx + self.ps, :]\n",
        "    gt_patch = gt_images[:, yy * 2:yy * 2 + self.ps * 2, xx * 2:xx * 2 + self.ps * 2, :]\n",
        "\n",
        "    if np.random.randint(2) == 1:  # random flip for rows\n",
        "      input_patch = np.flip(input_patch, axis=1)\n",
        "      gt_patch = np.flip(gt_patch, axis=1)\n",
        "    if np.random.randint(2) == 1:  # random flip for columns\n",
        "      input_patch = np.flip(input_patch, axis=2)\n",
        "      gt_patch = np.flip(gt_patch, axis=2)\n",
        "    if np.random.randint(2) == 1:  # random transpose\n",
        "      input_patch = np.transpose(input_patch, (0, 2, 1, 3))\n",
        "      gt_patch = np.transpose(gt_patch, (0, 2, 1, 3))\\\n",
        "\n",
        "    input_patch = np.minimum(input_patch, 1.0)\n",
        "    # print('generated an image with ind:',ind)\n",
        "\n",
        "    return (input_patch,gt_patch)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YECuKfSCS7JW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import datetime\n",
        "# class StoreEpochCallBack(tf.keras.callbacks.Callback):\n",
        "#   def __init__(self, params):\n",
        "#     self.f=open(params.epoch_num_file,\"w\")\n",
        "#   def on_train_batch_begin(self, batch, logs=None):\n",
        "#     print('Training: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))\n",
        "\n",
        "#   def on_train_batch_end(self, batch, logs=None):\n",
        "#     print('Training: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))\n",
        "\n",
        "#   def on_test_batch_begin(self, batch, logs=None):\n",
        "#     print('Evaluating: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))\n",
        "\n",
        "#   def on_test_batch_end(self, batch, logs=None):\n",
        "#     print('Evaluating: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))\n",
        "def learningratescheduler(epoch,lr):\n",
        "  if (epoch<50):\n",
        "    return 0.0005\n",
        "  elif (epoch>=50 and epoch<100):\n",
        "    return 0.0003\n",
        "  elif (epoch>=100 and epoch<1000):\n",
        "    return 0.0002\n",
        "  elif (epoch>=1000 and epoch<2000):\n",
        "    return 0.0001\n",
        "  else:\n",
        "    return 0.00001\n",
        "  \n",
        "\n",
        "def train_generator(model,data_gen,epochs,steps_per_epoch,save_fname,epoch_num_file,save_dir,tensorboard_log_dir):\n",
        "  print(\"Model Training started!!! Jay Yogeshwar!!!\")\n",
        "  last_epoch=0\n",
        "  last_line=\"\"\n",
        "  with open(epoch_num_file, mode='r', buffering=1) as begin_epoch_file:\n",
        "    last_line=list(begin_epoch_file)[-1]\n",
        "  last_epoch=json.loads(last_line)['epoch']\n",
        "  print(\"Epoch where last training ended:\",last_epoch)\n",
        "  if(last_epoch>10):\n",
        "    list_of_files=glob.glob(save_dir+\"*.hdf5\")\n",
        "    latest_file_path = max(list_of_files, key=os.path.getctime)\n",
        "    print (\"Latest saved model path:\",latest_file_path)\n",
        "    model.load_weights(latest_file_path)\n",
        "    last_epoch=int(latest_file_path.split('/')[-1].split('-')[-3])-11\n",
        "    print(\"Starting from epoch:\",(last_epoch+1))\n",
        "  else:\n",
        "    last_epoch=0\n",
        "  epoch_file=open(epoch_num_file, mode='a', buffering=1)\n",
        "  epoch_callback = keras.callbacks.LambdaCallback(\n",
        "    on_epoch_end=lambda epoch, logs: epoch_file.write(\n",
        "        json.dumps({'epoch': (epoch+1), 'loss': logs['loss'], 'datetime': (dt.datetime.now().strftime('%d%m%Y-%H%M%S'))}) + '\\n'),\n",
        "    on_train_end=lambda logs: epoch_file.close()\n",
        "  )\n",
        "  callbacks = [\n",
        "    epoch_callback,\n",
        "    ModelCheckpoint(period=1,filepath=save_fname, mode='min', monitor='loss', save_weights_only=True, verbose=1, save_best_only=True),\n",
        "#     TensorBoard(log_dir=tensorboard_log_dir),\n",
        "    LearningRateScheduler(learningratescheduler,verbose=1)\n",
        "  ]\n",
        "  model_history=model.fit_generator(\n",
        "      initial_epoch=last_epoch,\n",
        "      generator=data_gen,\n",
        "      steps_per_epoch=steps_per_epoch,\n",
        "      epochs=epochs,\n",
        "      callbacks=callbacks,\n",
        "      max_queue_size=5,\n",
        "      workers=2,\n",
        "      use_multiprocessing=True\n",
        "  )\n",
        "  print(\"Model Training completed!!! Jay Yogeshwar!!!\")\n",
        "  return model_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvdY4QQSpiKq",
        "colab_type": "code",
        "outputId": "37464f05-e185-49aa-a2df-daf14383689f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "  recall = true_positives / (possible_positives + K.epsilon())\n",
        "  return recall\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "  precision = true_positives / (predicted_positives + K.epsilon())\n",
        "  return precision\n",
        "\n",
        "def reduced_mean(y_true,y_pred):\n",
        "  return tf.reduce_mean(tf.abs(y_pred - y_true))\n",
        "\n",
        "\n",
        "params = Params()\n",
        "data = Data(params)\n",
        "dataloader = DataLoader(params,data)\n",
        "model=build_model()\n",
        "with open('model_summary.txt','w') as fh:\n",
        "    # Pass the file handle in as a lambda function to make it callable\n",
        "    model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
        "keras.utils.vis_utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "model.compile(optimizer=keras.optimizers.Adam(params.learning_rate),loss=reduced_mean,metrics=['accuracy'])\n",
        "steps_per_epoch=len(data.train_ids)\n",
        "# save_fname = os.path.join(params.save_dir, '%s-e%s.h5' % (dt.datetime.now().strftime('%d%m%Y-%H%M%S'), str(epochs)))\n",
        "save_fname = os.path.join(params.save_dir, '%s-weights-e-{epoch:02d}-l-{loss:.7f}.hdf5' % (dt.datetime.now().strftime('%d%m%Y-%H%M%S')))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0807 11:53:33.500993 140377882838912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0807 11:53:33.540231 140377882838912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0807 11:53:33.546923 140377882838912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0807 11:53:33.586875 140377882838912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total Train Ids: 161\n",
            "Sample Train Ids: [90, 91, 92, 72, 73, 75, 76, 78, 81, 83]\n",
            "Total Validation Ids: 20\n",
            "Sample Validation Ids: [20079, 20080, 20089, 20107, 20115, 20120, 20147, 20153, 20177, 20005]\n",
            "conv1 shape: (?, ?, ?, 32)\n",
            "conv1 shape: (?, ?, ?, 32)\n",
            "conv1 shape after pool: (?, ?, ?, 32)\n",
            "conv9 shape: (?, ?, ?, 32)\n",
            "conv10 shape: (?, ?, ?, 12)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0807 11:53:34.457552 140377882838912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoSXvhsPndeE",
        "colab_type": "code",
        "outputId": "2192ac81-4310-4a37-ab59-82220ef500e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dataloader.loadImages()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading gt_image id: 90\n",
            "loading gt_image id: 91\n",
            "loading gt_image id: 92\n",
            "loading gt_image id: 72\n",
            "loading gt_image id: 73\n",
            "loading gt_image id: 75\n",
            "loading gt_image id: 76\n",
            "loading gt_image id: 78\n",
            "loading gt_image id: 81\n",
            "loading gt_image id: 83\n",
            "loading gt_image id: 84\n",
            "loading gt_image id: 85\n",
            "loading gt_image id: 86\n",
            "loading gt_image id: 88\n",
            "loading gt_image id: 94\n",
            "loading gt_image id: 95\n",
            "loading gt_image id: 96\n",
            "loading gt_image id: 97\n",
            "loading gt_image id: 98\n",
            "loading gt_image id: 99\n",
            "loading gt_image id: 100\n",
            "loading gt_image id: 102\n",
            "loading gt_image id: 104\n",
            "loading gt_image id: 108\n",
            "loading gt_image id: 109\n",
            "loading gt_image id: 110\n",
            "loading gt_image id: 112\n",
            "loading gt_image id: 113\n",
            "loading gt_image id: 114\n",
            "loading gt_image id: 117\n",
            "loading gt_image id: 118\n",
            "loading gt_image id: 119\n",
            "loading gt_image id: 121\n",
            "loading gt_image id: 122\n",
            "loading gt_image id: 123\n",
            "loading gt_image id: 124\n",
            "loading gt_image id: 127\n",
            "loading gt_image id: 128\n",
            "loading gt_image id: 129\n",
            "loading gt_image id: 130\n",
            "loading gt_image id: 131\n",
            "loading gt_image id: 132\n",
            "loading gt_image id: 133\n",
            "loading gt_image id: 134\n",
            "loading gt_image id: 135\n",
            "loading gt_image id: 136\n",
            "loading gt_image id: 137\n",
            "loading gt_image id: 138\n",
            "loading gt_image id: 141\n",
            "loading gt_image id: 142\n",
            "loading gt_image id: 143\n",
            "loading gt_image id: 144\n",
            "loading gt_image id: 145\n",
            "loading gt_image id: 146\n",
            "loading gt_image id: 148\n",
            "loading gt_image id: 149\n",
            "loading gt_image id: 150\n",
            "loading gt_image id: 151\n",
            "loading gt_image id: 152\n",
            "loading gt_image id: 154\n",
            "loading gt_image id: 155\n",
            "loading gt_image id: 156\n",
            "loading gt_image id: 157\n",
            "loading gt_image id: 158\n",
            "loading gt_image id: 159\n",
            "loading gt_image id: 160\n",
            "loading gt_image id: 161\n",
            "loading gt_image id: 164\n",
            "loading gt_image id: 165\n",
            "loading gt_image id: 166\n",
            "loading gt_image id: 168\n",
            "loading gt_image id: 169\n",
            "loading gt_image id: 171\n",
            "loading gt_image id: 173\n",
            "loading gt_image id: 174\n",
            "loading gt_image id: 175\n",
            "loading gt_image id: 1\n",
            "loading gt_image id: 2\n",
            "loading gt_image id: 4\n",
            "loading gt_image id: 9\n",
            "loading gt_image id: 10\n",
            "loading gt_image id: 12\n",
            "loading gt_image id: 13\n",
            "loading gt_image id: 14\n",
            "loading gt_image id: 15\n",
            "loading gt_image id: 17\n",
            "loading gt_image id: 18\n",
            "loading gt_image id: 19\n",
            "loading gt_image id: 21\n",
            "loading gt_image id: 23\n",
            "loading gt_image id: 24\n",
            "loading gt_image id: 26\n",
            "loading gt_image id: 27\n",
            "loading gt_image id: 28\n",
            "loading gt_image id: 29\n",
            "loading gt_image id: 31\n",
            "loading gt_image id: 33\n",
            "loading gt_image id: 36\n",
            "loading gt_image id: 37\n",
            "loading gt_image id: 38\n",
            "loading gt_image id: 39\n",
            "loading gt_image id: 41\n",
            "loading gt_image id: 42\n",
            "loading gt_image id: 43\n",
            "loading gt_image id: 44\n",
            "loading gt_image id: 46\n",
            "loading gt_image id: 47\n",
            "loading gt_image id: 48\n",
            "loading gt_image id: 49\n",
            "loading gt_image id: 50\n",
            "loading gt_image id: 51\n",
            "loading gt_image id: 52\n",
            "loading gt_image id: 53\n",
            "loading gt_image id: 56\n",
            "loading gt_image id: 57\n",
            "loading gt_image id: 58\n",
            "loading gt_image id: 59\n",
            "loading gt_image id: 60\n",
            "loading gt_image id: 62\n",
            "loading gt_image id: 63\n",
            "loading gt_image id: 64\n",
            "loading gt_image id: 65\n",
            "loading gt_image id: 66\n",
            "loading gt_image id: 67\n",
            "loading gt_image id: 70\n",
            "loading gt_image id: 71\n",
            "loading gt_image id: 179\n",
            "loading gt_image id: 180\n",
            "loading gt_image id: 181\n",
            "loading gt_image id: 182\n",
            "loading gt_image id: 183\n",
            "loading gt_image id: 184\n",
            "loading gt_image id: 186\n",
            "loading gt_image id: 189\n",
            "loading gt_image id: 190\n",
            "loading gt_image id: 194\n",
            "loading gt_image id: 195\n",
            "loading gt_image id: 196\n",
            "loading gt_image id: 197\n",
            "loading gt_image id: 200\n",
            "loading gt_image id: 202\n",
            "loading gt_image id: 204\n",
            "loading gt_image id: 205\n",
            "loading gt_image id: 206\n",
            "loading gt_image id: 207\n",
            "loading gt_image id: 209\n",
            "loading gt_image id: 212\n",
            "loading gt_image id: 214\n",
            "loading gt_image id: 215\n",
            "loading gt_image id: 216\n",
            "loading gt_image id: 218\n",
            "loading gt_image id: 219\n",
            "loading gt_image id: 220\n",
            "loading gt_image id: 221\n",
            "loading gt_image id: 222\n",
            "loading gt_image id: 223\n",
            "loading gt_image id: 224\n",
            "loading gt_image id: 225\n",
            "loading gt_image id: 230\n",
            "loading gt_image id: 231\n",
            "loading gt_image id: 232\n",
            "gt_images loading done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ8IR20yraX8",
        "colab_type": "code",
        "outputId": "bc3db150-6fb1-4638-cec2-e7b5e534f0a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "source": [
        "\"\"\" ================ TRAIN THE MODEL ================ \"\"\"\n",
        "# steps_per_epoch=10\n",
        "model_history=train_generator(model,dataloader,params.epochs,steps_per_epoch,save_fname,params.epoch_file,params.save_dir,params.tensorboard_log_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Training started!!! Jay Yogeshwar!!!\n",
            "Epoch where last training ended: 15\n",
            "Latest saved model path: /content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/save_Sony/07082019-105227-weights-e-15-l-0.05.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0807 11:59:56.205843 140377882838912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0807 11:59:56.206919 140377882838912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting from epoch: 14\n",
            "Epoch 15/4000\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005.\n",
            "161/161 [==============================] - 109s 676ms/step - loss: 0.0577 - acc: 0.6868\n",
            "\n",
            "Epoch 00015: loss improved from inf to 0.05773, saving model to /content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/save_Sony/07082019-115334-weights-e-15-l-0.06.hdf5\n",
            "Epoch 16/4000\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005.\n",
            "102/161 [==================>...........] - ETA: 20s - loss: 0.0531 - acc: 0.6759"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6rt0FGT6jY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for epoch in range(lastepoch, 4001):\n",
        "#     #if os.path.isdir('result/%04d' % epoch):\n",
        "#     #    continue\n",
        "#     ###\n",
        "#     # used for skipping the current epoch if the checkpoint directory exists\n",
        "#     ###\n",
        "#     cnt = 0\n",
        "#     if epoch > 2000:\n",
        "#         learning_rate = 1e-5\n",
        "\n",
        "#     for ind in np.random.permutation(len(train_ids)):\n",
        "\n",
        "#         # get the path from image id\n",
        "\n",
        "#         train_id = train_ids[ind]\n",
        "#         in_files = glob.glob(input_dir + '%05d_00*.ARW' % train_id) # get all the images path with pattern 0*train_id\n",
        "#         in_path = in_files[np.random.randint(0, len(in_files))] # get any one image randomly\n",
        "#         in_fn = os.path.basename(in_path) # get only the full image name\n",
        "\n",
        "#         gt_files = glob.glob(gt_dir + '%05d_00*.ARW' % train_id) # get the ground truth image path(s) (only 1 may exist. hence select [0]th below)\n",
        "#         gt_path = gt_files[0] # get the first one (as only 1 gt image should exist)\n",
        "#         gt_fn = os.path.basename(gt_path) # get only the full image name for gt image\n",
        "#         in_exposure = float(in_fn[9:-5]) # get the exposure for input image\n",
        "#         gt_exposure = float(gt_fn[9:-5]) # get the exposure for gt image\n",
        "#         ratio = min(gt_exposure / in_exposure, 300) # get the amplification ratio\n",
        "\n",
        "#         st = time.time()\n",
        "#         cnt += 1\n",
        "\n",
        "#         if input_images[str(ratio)[0:3]][ind] is None: # if image is not loaded (first epoch), load it\n",
        "#             raw = rawpy.imread(in_path)\n",
        "#             input_images[str(ratio)[0:3]][ind] = \\\n",
        "#                 np.expand_dims(pack_raw(raw), axis=0) * ratio # pack the bayer image in 4 channels of RGBG\n",
        "\n",
        "#             gt_raw = rawpy.imread(gt_path)\n",
        "#             im = gt_raw.postprocess(use_camera_wb=True,\n",
        "#                                     half_size=False,\n",
        "#                                     no_auto_bright=True, output_bps=16)\n",
        "#             gt_images[ind] = np.expand_dims(np.float32(im / 65535.0),axis=0) # divide by 65535 to normalise (scale between 0 and 1)\n",
        "\n",
        "#         # crop\n",
        "\n",
        "#         H = input_images[str(ratio)[0:3]][ind].shape[1] # get the image height (number of rows)\n",
        "#         W = input_images[str(ratio)[0:3]][ind].shape[2] # get the image width (number of columns)\n",
        "\n",
        "#         xx = np.random.randint(0, W - ps) # get a random number in W-ps (W-512)\n",
        "#         yy = np.random.randint(0, H - ps) # get a random number in H-ps (H-512)\n",
        "#         input_patch = input_images[str(ratio)[0:3]][ind][:, yy:yy + ps,\n",
        "#                 xx:xx + ps, :]\n",
        "#         gt_patch = gt_images[ind][:, yy * 2:yy * 2 + ps * 2, xx * 2:xx\n",
        "#                                   * 2 + ps * 2, :]\n",
        "\n",
        "#         if np.random.randint(2) == 1:  # random flip for rows\n",
        "#             input_patch = np.flip(input_patch, axis=1)\n",
        "#             gt_patch = np.flip(gt_patch, axis=1)\n",
        "#         if np.random.randint(2) == 1:  # random flip for columns\n",
        "#             input_patch = np.flip(input_patch, axis=2)\n",
        "#             gt_patch = np.flip(gt_patch, axis=2)\n",
        "#         if np.random.randint(2) == 1:  # random transpose\n",
        "#             input_patch = np.transpose(input_patch, (0, 2, 1, 3))\n",
        "#             gt_patch = np.transpose(gt_patch, (0, 2, 1, 3))\\\n",
        "\n",
        "#         input_patch = np.minimum(input_patch, 1.0)\n",
        "\n",
        "#         (_, G_current, output) = sess.run([G_opt, G_loss, out_image],\n",
        "#                 feed_dict={in_image: input_patch, gt_image: gt_patch,\n",
        "#                 lr: learning_rate})\n",
        "#         output = np.minimum(np.maximum(output, 0), 1)\n",
        "#         g_loss[ind] = G_current\n",
        "\n",
        "#         print '%d %d Loss=%.3f Time=%.3f' % (epoch, cnt,\n",
        "#                 np.mean(g_loss[np.where(g_loss)]), time.time() - st)\n",
        "\n",
        "#         if epoch % save_freq == 0:\n",
        "#             if not os.path.isdir(result_dir + '%04d' % epoch):\n",
        "#                 os.makedirs(result_dir + '%04d' % epoch)\n",
        "\n",
        "#             temp = np.concatenate((gt_patch[0, :, :, :], output[0, :, :\n",
        "#                                   , :]), axis=1)\n",
        "#             scipy.misc.toimage(temp * 255, high=255, low=0, cmin=0,\n",
        "#                                cmax=255).save(result_dir\n",
        "#                     + '%04d/%05d_00_train_%d.jpg' % (epoch, train_id,\n",
        "#                     ratio))\n",
        "\n",
        "#     saver.save(sess, checkpoint_dir + 'model.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir4Xcjn_mfhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import multiprocessing\n",
        "\n",
        "multiprocessing.gpu_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N63_LgRdETgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %tensorboard --logdir '/content/drive/My Drive/Data/SeeInDarkDataset/dataset/Sony/tensorboard'\n",
        "# from tensorboard import notebook\n",
        "# notebook.list() # View open TensorBoard instances\n",
        "# notebook.display(port=6006, height=1000) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}